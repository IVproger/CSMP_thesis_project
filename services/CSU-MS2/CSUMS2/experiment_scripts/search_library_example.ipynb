{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94f7e24",
   "metadata": {},
   "source": [
    "# CSU-MS2 cross-modal retireval \n",
    "### importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5bb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow to import modules from the project root directory\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root directory to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbd6f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "from infer import ModelInference\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from matchms.importing import load_from_mgf\n",
    "from matchms.Fragments import Fragments\n",
    "import pandas as pd\n",
    "import IsoSpecPy\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import pubchempy as pc\n",
    "from bs4 import BeautifulSoup\n",
    "import matchms.filtering as msfilters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6c44fb",
   "metadata": {},
   "source": [
    "### define spectrum processing function and reference dataset searching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e9262f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_processing(s):\n",
    "    \"\"\"This is how one would typically design a desired pre- and post-\n",
    "    processing pipeline.\"\"\"\n",
    "    s = msfilters.normalize_intensities(s)\n",
    "    s = msfilters.select_by_mz(s, mz_from=0, mz_to=1500)\n",
    "    return s\n",
    "\n",
    "def search_formula(formulaDB,mass, ppm): \n",
    "    mmin = mass - mass*ppm/10**6 \n",
    "    mmax = mass + mass*ppm/10**6 \n",
    "    lf = bisect.bisect_left(formulaDB['Exact mass'], mmin) \n",
    "    rg = bisect.bisect_right(formulaDB['Exact mass'], mmax) \n",
    "    formulas = list(formulaDB['Formula'][lf:rg]) \n",
    "    return formulas \n",
    "\n",
    "def search_structure(structureDB,formulas): \n",
    "    structures=pd.DataFrame()\n",
    "    for formula in formulas:\n",
    "        structure = structureDB[structureDB['MolecularFormula']==formula] \n",
    "        structures=pd.concat([structures,structure])\n",
    "    return structures \n",
    "\n",
    "def search_structure_from_mass(structureDB,mass, ppm): \n",
    "    structures=pd.DataFrame()\n",
    "    # mmin = mass - mass*ppm/10**6 \n",
    "    # mmax = mass + mass*ppm/10**6 \n",
    "    # print(mmin, mmax)\n",
    "    # structures = structureDB[(structureDB['MonoisotopicMass'] >= mmin) & (structureDB['MonoisotopicMass'] <= mmax)]\n",
    "    return structureDB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea08522",
   "metadata": {},
   "source": [
    "### define structural feature vector calculation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b171dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code\n",
    "# def get_feature(lst,save_name,model_inference,\n",
    "#                 n=256,flag_get_value=False):\n",
    "\n",
    "#     print(\"Size of the library: \", len(lst))\n",
    "#     fn = model_inference.smiles_encode\n",
    "#     contexts = []\n",
    "\n",
    "\n",
    "#     print(\"start load batch\")\n",
    "#     for i in range(0, len(lst), n):\n",
    "#        contexts.append(lst[i:i + n])\n",
    "\n",
    "#     print(\"start encode batch\")\n",
    "#     result = [fn(i).cpu() for i in tqdm(contexts)]\n",
    "#     result = torch.cat(result, 0)\n",
    "#     if flag_get_value is True:\n",
    "#         if save_name is not None:\n",
    "#             torch.save((result, lst), save_name)\n",
    "#         return result, lst\n",
    "\n",
    "def get_feature(lst, save_name, model_inference, n=256, flag_get_value=False):\n",
    "    print(\"Size of the library: \", len(lst))\n",
    "    fn = model_inference.smiles_encode\n",
    "    contexts = []\n",
    "\n",
    "    print(\"start load batch\")\n",
    "    for i in range(0, len(lst), n):\n",
    "        batch = lst[i:i + n]\n",
    "        contexts.append(batch)\n",
    "        # print(f\"Created batch {len(contexts)}: items {i} to {i + len(batch) - 1} (size: {len(batch)})\")\n",
    "\n",
    "\n",
    "    print(\"start encode batch\")\n",
    "    result = []\n",
    "    total_batches = len(contexts)\n",
    "    print(\"Total_batches: \", total_batches)\n",
    "    for i, context in enumerate(contexts):\n",
    "        batch_result = fn(context).cpu()\n",
    "        result.append(batch_result)\n",
    "        \n",
    "        # Print progress every 10% or every 10 batches\n",
    "        if (i + 1) % max(1, total_batches // 10) == 0 or i + 1 == total_batches:\n",
    "            progress = ((i + 1) / total_batches) * 100\n",
    "            print(f\"Progress: {i + 1}/{total_batches} batches ({progress:.1f}%)\")\n",
    "    \n",
    "    result = torch.cat(result, 0)\n",
    "    if flag_get_value is True:\n",
    "        if save_name is not None:\n",
    "            torch.save((result, lst), save_name)\n",
    "        return result, lst\n",
    "\n",
    "\n",
    "def get_topK_result(library,ms_feature, smiles_feature, topK):\n",
    "    indices = []\n",
    "    scores = []\n",
    "    candidates = []\n",
    "    if topK >= len(library):\n",
    "        topK = len(library)\n",
    "    with torch.no_grad():\n",
    "        ms_smiles_distances_tmp = (\n",
    "            ms_feature @ smiles_feature.t()).cpu()\n",
    "        scores_, indices_ = ms_smiles_distances_tmp.topk(topK,\n",
    "                                                      dim=1,\n",
    "                                                      largest=True,\n",
    "                                                      sorted=True)\n",
    "        candidates_=[library[i] for i in indices_.tolist()[0]]\n",
    "        indices.append(indices_.tolist()[0])\n",
    "        scores.append(scores_.tolist()[0])\n",
    "        candidates.append(candidates_)\n",
    "    return indices, scores, candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f8ece",
   "metadata": {},
   "source": [
    "### loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dece960",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path_low = \"model/hcd_model/low_energy/checkpoints/config.yaml\"\n",
    "pretrain_model_path_low = \"model/hcd_model/low_energy/checkpoints/model.pth\"\n",
    "model_inference_low = ModelInference(config_path=config_path_low,\n",
    "                            pretrain_model_path=pretrain_model_path_low,\n",
    "                            device=\"cpu\")\n",
    "config_path_median = \"model/hcd_model/median_energy/checkpoints/config.yaml\"\n",
    "pretrain_model_path_median = \"model/hcd_model/median_energy/checkpoints/model.pth\"\n",
    "model_inference_median = ModelInference(config_path=config_path_median,\n",
    "                            pretrain_model_path=pretrain_model_path_median,\n",
    "                            device=\"cpu\")\n",
    "config_path_high = \"model/hcd_model/high_energy/checkpoints/config.yaml\"\n",
    "pretrain_model_path_high = \"model/hcd_model/high_energy/checkpoints/model.pth\"\n",
    "model_inference_high = ModelInference(config_path=config_path_high,\n",
    "                            pretrain_model_path=pretrain_model_path_high,\n",
    "                            device=\"cpu\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a311d4",
   "metadata": {},
   "source": [
    "### create result save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4e692e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_file='results/'\n",
    "os.mkdir(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f95699",
   "metadata": {},
   "source": [
    "### upload spectra file, reference dataset file and collision energy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4974eb3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ms_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(load_from_mgf(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/test_spectrum.mgf\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m reference_library \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../notebooks/output.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# collision_energy_file=pd.read_csv('collision_energy.csv')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# collision_energy_lst = list(collision_energy_file['CollisionEnergy'])\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1036\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1090\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1165\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1335\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1331\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1332\u001b[0m     )\n\u001b[0;32m-> 1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ms_list=list(load_from_mgf(\"data/test_spectrum.mgf\"))\n",
    "reference_library = pd.read_csv('../../notebooks/output.csv')\n",
    "# collision_energy_file=pd.read_csv('collision_energy.csv')\n",
    "# collision_energy_lst = list(collision_energy_file['CollisionEnergy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab92979",
   "metadata": {},
   "source": [
    " ### perform cross-modal retrieval for a list of spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "689be17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smiles_feature_low prediction:\n",
      "Size of the library:  1000\n",
      "start encode batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Encoding SMILES:   0%|          | 0/1000 [00:06<?, ?it/s]\n",
      "  0%|          | 0/1 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m smiles_lst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(search_res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMILES\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmiles_feature_low prediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m smiles_feature_low, smiles_lst1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmiles_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_inference_low\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mflag_get_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmiles_feature_median prediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m smiles_feature_median, smiles_lst2 \u001b[38;5;241m=\u001b[39m get_feature(smiles_lst,save_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m     model_inference\u001b[38;5;241m=\u001b[39mmodel_inference_median,n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,flag_get_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[61], line 64\u001b[0m, in \u001b[0;36mget_feature\u001b[0;34m(lst, save_name, model_inference, n, flag_get_value)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(lst), n):\n\u001b[1;32m     63\u001b[0m     batch \u001b[38;5;241m=\u001b[39m lst[i:i \u001b[38;5;241m+\u001b[39m n]\n\u001b[0;32m---> 64\u001b[0m     batch_result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     65\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(batch_result)\n\u001b[1;32m     66\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(batch))  \u001b[38;5;66;03m# Update by actual number of items processed\u001b[39;00m\n",
      "File \u001b[0;32m~/csmp_search_engine_for_specmol/CSMP_thesis_project/services/CSU-MS2/infer.py:49\u001b[0m, in \u001b[0;36mModelInference.smiles_encode\u001b[0;34m(self, smiles_str)\u001b[0m\n\u001b[1;32m     47\u001b[0m v_ds \u001b[38;5;241m=\u001b[39m v_ds\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     48\u001b[0m smiles_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msmiles_encoder(v_ds)\n\u001b[0;32m---> 49\u001b[0m smiles_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmi_esa\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmiles_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m smiles_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msmi_proj(smiles_tensor)\n\u001b[1;32m     51\u001b[0m smiles_tensor \u001b[38;5;241m=\u001b[39m smiles_tensor\u001b[38;5;241m/\u001b[39msmiles_tensor\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/csmp_search_engine_for_specmol/CSMP_thesis_project/services/CSU-MS2/CSUMS2/model.py:226\u001b[0m, in \u001b[0;36mESA_SMILES.forward\u001b[0;34m(self, hidden_states, data_batch)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(B):\n\u001b[1;32m    225\u001b[0m     indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(data_batch \u001b[38;5;241m==\u001b[39m i)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 226\u001b[0m     result[i, :\u001b[38;5;28mlen\u001b[39m(indices), :] \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    227\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m (result \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat() \n\u001b[1;32m    228\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_f(result) \u001b[38;5;66;03m# (B, N, C)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(ms_list))):\n",
    "            result=pd.DataFrame()\n",
    "            spectrum = ms_list[i]\n",
    "            spectrum = spectrum_processing(spectrum)\n",
    "            ms_feature_low = model_inference_low.ms2_encode([spectrum])\n",
    "            ms_feature_median = model_inference_median.ms2_encode([spectrum])\n",
    "            ms_feature_high = model_inference_high.ms2_encode([spectrum])\n",
    "            \n",
    "            # The precursor mass and collison energy can also be set manually \n",
    "            query_ms = float(spectrum.metadata['precursor_mz'])-1.008\n",
    "            collision_energy = int(spectrum.metadata.get('collision_energy', 20)) \n",
    "            # collision_energy = collision_energy_lst[i]\n",
    "            search_res=search_structure_from_mass(reference_library, query_ms, 30)\n",
    "            smiles_lst = list(search_res['SMILES'])\n",
    "\n",
    "            print(\"smiles_feature_low prediction:\")\n",
    "            smiles_feature_low, smiles_lst1 = get_feature(smiles_lst,save_name=None,\n",
    "                model_inference=model_inference_low,n=256,flag_get_value=True)\n",
    "            \n",
    "            print(\"smiles_feature_median prediction:\")\n",
    "            smiles_feature_median, smiles_lst2 = get_feature(smiles_lst,save_name=None,\n",
    "                model_inference=model_inference_median,n=256,flag_get_value=True)\n",
    "            \n",
    "            print(\"smiles_feature_high prediction:\")\n",
    "            smiles_feature_high, smiles_lst3 = get_feature(smiles_lst,save_name=None,\n",
    "                model_inference=model_inference_high,n=256,flag_get_value=True)\n",
    "            \n",
    "            low_similarity = ms_feature_low @ smiles_feature_low.t()\n",
    "            median_similarity = ms_feature_median @ smiles_feature_median.t()\n",
    "            high_similarity = ms_feature_high @ smiles_feature_high.t()\n",
    "            low_similarity = low_similarity.numpy()\n",
    "            median_similarity = median_similarity.numpy()\n",
    "            high_similarity = high_similarity.numpy()\n",
    "            \n",
    "            weight1 = (1/abs(collision_energy-10+1e-10))/((1/abs(collision_energy-10+1e-10))+(1/abs(collision_energy-20+1e-10))+(1/abs(collision_energy-40+1e-10)))\n",
    "            weight2 = (1/abs(collision_energy-20+1e-10))/((1/abs(collision_energy-10+1e-10))+(1/abs(collision_energy-20+1e-10))+(1/abs(collision_energy-40+1e-10)))\n",
    "            weight3 = (1/abs(collision_energy-40+1e-10))/((1/abs(collision_energy-10+1e-10))+(1/abs(collision_energy-20+1e-10))+(1/abs(collision_energy-40+1e-10)))\n",
    "   \n",
    "            weighted_similarity = weight1 * low_similarity + weight2 * median_similarity + weight3 * high_similarity\n",
    "            weighted_similarity = np.squeeze(weighted_similarity, axis=0)\n",
    "            weighted_similarity_scores=[(smiles_lst1[i],weighted_similarity[i]) for i in range(len(smiles_lst1))]\n",
    "            weighted_similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "            results = pd.DataFrame({'SMILES':[x[0] for x in weighted_similarity_scores],'Score':[x[1] for x in weighted_similarity_scores],'Rank':list(range(1,len(smiles_lst1)+1))})\n",
    "            results.to_csv(output_file+'spectrum'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e6717a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              SMILES     Score  Rank\n",
      "0  C=C[C@@]1(C)CC(=O)[C@]2(O)[C@@]3(C)[C@@H](O)CC...  0.667050     1\n",
      "1  CO/C1=C\\C(C)=C\\[C@@H](C)[C@@H](O)[C@@H](C)C/C(...  0.665769     2\n",
      "2  C=C1[C@@H](O)[C@@H]2O[C@]3(CC[C@H](/C=C/[C@@H]...  0.661226     3\n",
      "3  CC[C@@]1([C@@H]2O[C@@H]([C@H]3O[C@@](O)(CO)[C@...  0.649401     4\n",
      "4  CO[C@@H]1C[C@@H](C[C@H]2CC[C@H](C)[C@H]([C@@H]...  0.642349     5\n"
     ]
    }
   ],
   "source": [
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f701c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "import pandas as pd\n",
    "\n",
    "def compute_tanimoto_similarity(target_smiles, results_df):\n",
    "    \"\"\"\n",
    "    Compute Tanimoto similarity between target SMILES and each SMILES in results DataFrame\n",
    "    \"\"\"\n",
    "    # Convert target SMILES to molecule and fingerprint\n",
    "    target_mol = Chem.MolFromSmiles(target_smiles)\n",
    "    if target_mol is None:\n",
    "        print(f\"Warning: Could not parse target SMILES: {target_smiles}\")\n",
    "        return results_df\n",
    "    \n",
    "    target_fp = rdMolDescriptors.GetMorganFingerprintAsBitVect(target_mol, 2, nBits=2048)\n",
    "    \n",
    "    tanimoto_scores = []\n",
    "    \n",
    "    for smiles in results_df['SMILES']:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            tanimoto_scores.append(0.0)  # Invalid SMILES gets 0 similarity\n",
    "            continue\n",
    "        \n",
    "        # Generate Morgan fingerprint\n",
    "        fp = rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "        \n",
    "        # Calculate Tanimoto similarity\n",
    "        tanimoto = DataStructs.TanimotoSimilarity(target_fp, fp)\n",
    "        tanimoto_scores.append(tanimoto)\n",
    "    \n",
    "    # Add Tanimoto similarity to results DataFrame\n",
    "    results_df = results_df.copy()\n",
    "    results_df['Tanimoto_Similarity'] = tanimoto_scores\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c4927ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                SMILES     Score  Rank  \\\n",
      "791              NC(=O)c1ccccc1Nc1ccnc(Nc2cccc(O)c2)n1 -0.089166   792   \n",
      "679    C[C@@H](Oc1ccc(Oc2ncc(C(F)(F)F)cc2Cl)cc1)C(=O)O -0.036087   680   \n",
      "786                         O=C(O)C(=O)Nc1ccccc1C(=O)O -0.085290   787   \n",
      "568  CC(C)[C@H](CO)Nc1nc(Nc2ccc(C(=O)O)c(Cl)c2)c2nc...  0.018972   569   \n",
      "374  O=C(NC(=O)c1c(F)cccc1F)Nc1ccc(Cl)c(Oc2ncc(C(F)...  0.138712   375   \n",
      "\n",
      "     Tanimoto_Similarity  \n",
      "791             0.301587  \n",
      "679             0.265625  \n",
      "786             0.265306  \n",
      "568             0.263158  \n",
      "374             0.260274  \n"
     ]
    }
   ],
   "source": [
    "# Usage example:\n",
    "spectrum = ms_list[0]\n",
    "target_smiles = spectrum.metadata['smiles']\n",
    "results_with_tanimoto = compute_tanimoto_similarity(target_smiles, results)\n",
    "\n",
    "# You can also sort by Tanimoto similarity\n",
    "results_sorted_by_tanimoto = results_with_tanimoto.sort_values('Tanimoto_Similarity', ascending=False)\n",
    "print(results_sorted_by_tanimoto.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "03fd536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Score</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Tanimoto_Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>NC(=O)c1ccccc1Nc1ccnc(Nc2cccc(O)c2)n1</td>\n",
       "      <td>-0.089166</td>\n",
       "      <td>792</td>\n",
       "      <td>0.301587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>C[C@@H](Oc1ccc(Oc2ncc(C(F)(F)F)cc2Cl)cc1)C(=O)O</td>\n",
       "      <td>-0.036087</td>\n",
       "      <td>680</td>\n",
       "      <td>0.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>O=C(O)C(=O)Nc1ccccc1C(=O)O</td>\n",
       "      <td>-0.085290</td>\n",
       "      <td>787</td>\n",
       "      <td>0.265306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>CC(C)[C@H](CO)Nc1nc(Nc2ccc(C(=O)O)c(Cl)c2)c2nc...</td>\n",
       "      <td>0.018972</td>\n",
       "      <td>569</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>O=C(NC(=O)c1c(F)cccc1F)Nc1ccc(Cl)c(Oc2ncc(C(F)...</td>\n",
       "      <td>0.138712</td>\n",
       "      <td>375</td>\n",
       "      <td>0.260274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>COCCOCCOCCOCCOCCOC</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>COCCOCCOCCOC</td>\n",
       "      <td>-0.247590</td>\n",
       "      <td>968</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>Cl[Cu]Cl</td>\n",
       "      <td>-0.249652</td>\n",
       "      <td>969</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>CCOCCOCCOCCOCCOCCOCC</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>593</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>C[N+](C)(C)C</td>\n",
       "      <td>-0.437650</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SMILES     Score  Rank  \\\n",
       "791              NC(=O)c1ccccc1Nc1ccnc(Nc2cccc(O)c2)n1 -0.089166   792   \n",
       "679    C[C@@H](Oc1ccc(Oc2ncc(C(F)(F)F)cc2Cl)cc1)C(=O)O -0.036087   680   \n",
       "786                         O=C(O)C(=O)Nc1ccccc1C(=O)O -0.085290   787   \n",
       "568  CC(C)[C@H](CO)Nc1nc(Nc2ccc(C(=O)O)c(Cl)c2)c2nc...  0.018972   569   \n",
       "374  O=C(NC(=O)c1c(F)cccc1F)Nc1ccc(Cl)c(Oc2ncc(C(F)...  0.138712   375   \n",
       "..                                                 ...       ...   ...   \n",
       "599                                 COCCOCCOCCOCCOCCOC  0.005190   600   \n",
       "967                                       COCCOCCOCCOC -0.247590   968   \n",
       "968                                           Cl[Cu]Cl -0.249652   969   \n",
       "592                               CCOCCOCCOCCOCCOCCOCC  0.007715   593   \n",
       "999                                       C[N+](C)(C)C -0.437650  1000   \n",
       "\n",
       "     Tanimoto_Similarity  \n",
       "791             0.301587  \n",
       "679             0.265625  \n",
       "786             0.265306  \n",
       "568             0.263158  \n",
       "374             0.260274  \n",
       "..                   ...  \n",
       "599             0.000000  \n",
       "967             0.000000  \n",
       "968             0.000000  \n",
       "592             0.000000  \n",
       "999             0.000000  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sorted_by_tanimoto"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSU-MS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b03b062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import your model and data loading components\n",
    "from dataloader.dataset_wrapper import create_wrapper_from_dataframe\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dcf179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (Metal Performance Shaders) for GPU acceleration\n",
      "Using device: mps\n",
      "Validation data path: /Users/ivangolov/Desktop/Диплом/CSMP_project/CSMP_spectrum_database/data/production/train_deduplicated.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration and paths setup\n",
    "CONFIG_PATH = \"/Users/ivangolov/Desktop/Диплом/CSMP_project/CSMP_thesis_project/services/CSU-MS2/model/qtof_model/median_energy/checkpoints/config.yaml\"\n",
    "TRAIN_CSV_PATH = \"/Users/ivangolov/Desktop/Диплом/CSMP_project/CSMP_spectrum_database/data/production/train_deduplicated.csv\"\n",
    "OUTPUT_DIR = \"./train_results\"\n",
    "\n",
    "# Device selection for Mac\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "    print(\"Using MPS (Metal Performance Shaders) for GPU acceleration\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "    print(\"Using CUDA for GPU acceleration\")\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Validation data path: {TRAIN_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38c5767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration...\n",
      "Configuration loaded:\n",
      "- Batch size: 64\n",
      "- Model config keys: []\n",
      "- Loss config: {'temperature': 0.1, 'use_cosine_similarity': True, 'alpha_weight': 0.75}\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load configuration\n",
    "print(\"Loading configuration...\")\n",
    "config = yaml.load(open(CONFIG_PATH, \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Batch size: {config.get('batch_size', 'Not specified')}\")\n",
    "print(f\"- Model config keys: {list(config.get('model', {}).keys())}\")\n",
    "print(f\"- Loss config: {config.get('loss', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd12ab82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "Validation dataset shape: (798444, 10)\n",
      "Columns: ['peaks_json', 'ion_source', 'compound_source', 'instrument', 'adduct', 'precursor_mz', 'smiles', 'inchikey', 'ion_mode', 'molecular_formula']\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peaks_json</th>\n",
       "      <th>ion_source</th>\n",
       "      <th>compound_source</th>\n",
       "      <th>instrument</th>\n",
       "      <th>adduct</th>\n",
       "      <th>precursor_mz</th>\n",
       "      <th>smiles</th>\n",
       "      <th>inchikey</th>\n",
       "      <th>ion_mode</th>\n",
       "      <th>molecular_formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[42.014248, 0.10199999999999998], [42.26601, ...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[49.01717, 0.155], [49.020023, 0.253], [67.05...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[49.017338, 0.242], [49.020237, 0.181], [67.0...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[49.01701, 0.144], [49.019947, 0.244], [139.0...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[49.017166, 0.155], [49.020008, 0.253], [139....</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          peaks_json ion_source  \\\n",
       "0  [[42.014248, 0.10199999999999998], [42.26601, ...        ESI   \n",
       "1  [[49.01717, 0.155], [49.020023, 0.253], [67.05...        ESI   \n",
       "2  [[49.017338, 0.242], [49.020237, 0.181], [67.0...        ESI   \n",
       "3  [[49.01701, 0.144], [49.019947, 0.244], [139.0...        ESI   \n",
       "4  [[49.017166, 0.155], [49.020008, 0.253], [139....        ESI   \n",
       "\n",
       "  compound_source instrument  adduct  precursor_mz  \\\n",
       "0           Crude   Orbitrap  [M+H]+       377.186   \n",
       "1           Crude   Orbitrap  [M+H]+       377.186   \n",
       "2           Crude   Orbitrap  [M+H]+       377.186   \n",
       "3           Crude   Orbitrap  [M+H]+       377.186   \n",
       "4           Crude   Orbitrap  [M+H]+       377.186   \n",
       "\n",
       "                                              smiles  \\\n",
       "0  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "1  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "2  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "3  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "4  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "\n",
       "                      inchikey  ion_mode molecular_formula  \n",
       "0  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "1  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "2  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "3  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "4  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Load and explore validation data\n",
    "print(\"Loading train data...\")\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "\n",
    "print(f\"Validation dataset shape: {df_train.shape}\")\n",
    "print(f\"Columns: {list(df_train.columns)}\")\n",
    "print(f\"Sample data:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fda3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample = df_train.sample(n=10000,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3829c1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data loaders\n",
      "Convert DataFrame to compatible files\n",
      "Processed 10000 valid spectra out of 10000 total entries.\n",
      "Create data wrapper\n",
      "calculating molecular graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1033/8000 [00:00<00:04, 1515.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1738/8000 [00:01<00:03, 1708.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C2=CC=C(O)C(=C2OC(=C1C=3C=CC=4OCCCOC4C3)C)C[NH+](C)C calculation failure\n",
      "SMILES [Na+].O=C(CCCCCCCCCCC)CC(O)S(=O)(=O)[O-] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2086/8000 [00:01<00:03, 1714.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C(=COC2=C1C=C(C(O)=C2C[NH+](C)C)CC)C=3C=CC=4OCCOC4C3 calculation failure\n",
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 2431/8000 [00:01<00:03, 1708.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].OC=1C=C(O)C=2C=C(OC3OC(CO)C(O)C(O)C3O)C(=[O+]C2C1)C=4C=CC(O)=C(O)C4 calculation failure\n",
      "SMILES [Cl-].O=C1C2=CC=C(O)C(=C2OC(=C1C=3C=CC=4OCCCOC4C3)C)C[NH+](C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2946/8000 [00:01<00:02, 1702.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C=2C=C(C(O)=C(C2OC(=C1C=3C=CC=4OCCOC4C3)C)C[NH+](C)C)CCC calculation failure\n",
      "SMILES [K+].O=S(=O)([O-])ON=C(SC1OC(CO)C(O)C(O)C1O)CC=C.O calculation failure\n",
      "SMILES [Na+].O=C(CCCCCCCCCCC)CC(O)S(=O)(=O)[O-] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 4499/8000 [00:02<00:02, 1691.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C2=CC=C(O)C(=C2OC(=C1C=3C=CC=4OCCCOC4C3)C)C[NH+](C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5002/8000 [00:03<00:01, 1641.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [K+].[K+].O=C([O-])C1OC(OC2C(OC(C(=O)[O-])C(O)C2O)OC3CCC4(C)C5C(=O)C=C6C7CC(C(=O)O)(C)CCC7(C)CCC6(C)C5(C)CCC4C3(C)C)C(O)C(O)C1O calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 5644/8000 [00:03<00:01, 1408.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].OC=1C=C(O)C=2C=C(OC3OC(CO)C(O)C(O)C3O)C(=[O+]C2C1)C=4C=CC(O)=C(O)C4 calculation failure\n",
      "SMILES C1C(N(C2=C(N1)N=C(NC2=O)N)C=O)CNC3=CC=C(C=C3)C(=O)N[C@@H](CCC(=O)[O-])C(=O)[O-].[Ca+2] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 6183/8000 [00:03<00:01, 1179.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=C([O-])C(CC)C1OC(C(=CC=CC2C=CC3CCCC3C2C(=O)C4=CC=CN4)CC)C(C)CC1 calculation failure\n",
      "SMILES [K+].O=C([O-])C12CCC(C(=C)C)C2C3CCC4C5(C)CCC(=O)C(C)(C)C5CCC4(C)C3(C)CC1 calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 7265/8000 [00:04<00:00, 1546.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=P([O-])(O)OCC1OC(N2C=NC=3C(=NC=NC32)N)C(O)C1O calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:05<00:00, 1544.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n",
      "Calculated 6848 molecular graph-mass spectrometry pairs\n",
      "calculating molecular graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 495/2000 [00:00<00:00, 1652.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C(O)C=1C=CC=CC1C=2C=3C=CC(=CC3OC4=CC(C=CC42)=[N+](CC)CC)N(CC)CC calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 994/2000 [00:00<00:00, 1647.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=C(CCCCCCCCCCC)CC(O)S(=O)(=O)[O-] calculation failure\n",
      "SMILES [K+].O=S(=O)([O-])ON=C(SC1OC(CO)C(O)C(O)C1O)CC=C.O calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1837/2000 [00:01<00:00, 1679.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Br-].O=C(OC1CC2C3OC3C(C1)[N+]2(C)CCCC)C(C=4C=CC=CC4)CO calculation failure\n",
      "SMILES CCC1=C(C2=NC1=CC3=C(C4=C([N-]3)C(=C5[C@H]([C@@H](C(=N5)C=C6C(=C(C(=C2)[N-]6)C=C)C)C)CCC(=O)OC/C=C(\\C)/CCC[C@H](C)CCC[C@H](C)CCCC(C)C)[C@H](C4=O)C(=O)OC)C)C=O.[Mg+2] calculation failure\n",
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1644.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 1705 molecular graph-mass spectrometry pairs\n",
      "Successfully processed 10000 samples\n",
      "Number of batches: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Prepare validation data loader\n",
    "print(\"Preparing data loaders\")\n",
    "\n",
    "# Create data wrapper from DataFrame\n",
    "wrapper, processed_df = create_wrapper_from_dataframe(\n",
    "    df=df_train_sample,\n",
    "    batch_size=64,  \n",
    "    num_workers=8,\n",
    "    valid_size=0.2,  \n",
    "    use_ddp=False,\n",
    "    output_dir=\"./train_features\",\n",
    ")\n",
    "\n",
    "# Get the data loader\n",
    "train_loader, val_loader = wrapper.get_data_loaders()\n",
    "\n",
    "print(f\"Successfully processed {len(processed_df)} samples\")\n",
    "print(f\"Number of batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7fba6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ModelCLR\n",
    "\n",
    "# Initialize model architecture\n",
    "model = ModelCLR(**config[\"model_config\"]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4012a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ARCHITECTURE:\n",
      "----------------------------------------\n",
      "Model Type: ModelCLR\n",
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture Overview\n",
    "print(\"MODEL ARCHITECTURE:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Model Type: {type(model).__name__}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c8beedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBMODULES:\n",
      "----------------------------------------\n",
      "Smiles_model   : SmilesModel\n",
      "  training    : True\n",
      "  num_layer   : 5\n",
      "  emb_dim     : 300\n",
      "  feat_dim    : 512\n",
      "  drop_ratio  : 0.3\n",
      "MS_model       : MSModel\n",
      "  training    : True\n",
      "smi_esa        : ESA_SMILES\n",
      "  training    : True\n",
      "spec_esa       : ESA_SPEC\n",
      "  training    : True\n",
      "smi_proj       : Linear\n",
      "  training    : True\n",
      "  in_features : 256\n",
      "  out_features: 256\n",
      "spec_proj      : Linear\n",
      "  training    : True\n",
      "  in_features : 256\n",
      "  out_features: 256\n"
     ]
    }
   ],
   "source": [
    "# Submodules Analysis\n",
    "print(\"SUBMODULES:\")\n",
    "print(\"-\" * 40)\n",
    "for name, module in model.named_children():\n",
    "    print(f\"{name:15}: {type(module).__name__}\")\n",
    "    if hasattr(module, '__dict__'):\n",
    "        for attr_name, attr_value in module.__dict__.items():\n",
    "            if not attr_name.startswith('_') and not callable(attr_value):\n",
    "                if isinstance(attr_value, (int, float, str, bool)):\n",
    "                    print(f\"  {attr_name:12}: {attr_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25f14f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ANALYSIS:\n",
      "----------------------------------------\n",
      "Total Parameters: 5,318,572\n",
      "Trainable Parameters: 5,318,444\n",
      "Non-trainable Parameters: 128\n"
     ]
    }
   ],
   "source": [
    "# Parameter Count\n",
    "print(\"PARAMETER ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable Parameters: {total_params - trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "451b63b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY ANALYSIS:\n",
      "----------------------------------------\n",
      "Model Size: 20.30 MB\n",
      "Parameter Memory: 20.29 MB\n",
      "Buffer Memory: 0.01 MB\n"
     ]
    }
   ],
   "source": [
    "# Memory Usage (approximate)\n",
    "print(\"MEMORY ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "model_size_mb = (param_size + buffer_size) / 1024 / 1024\n",
    "\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"Parameter Memory: {param_size / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Buffer Memory: {buffer_size / 1024 / 1024:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44da99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss.nt_xent import NTXentLoss\n",
    "\n",
    "# Initialize loss function\n",
    "temperature = config.get('loss', {}).get('temperature', 0.1)\n",
    "batch_size = config.get('batch_size', 1024)\n",
    "use_cosine_similarity = config.get('loss', {}).get('use_cosine_similarity', True)\n",
    "alpha_weight = config.get('loss', {}).get('alpha_weight', 1.0)\n",
    "\n",
    "criterion = NTXentLoss(\n",
    "    device=DEVICE, \n",
    "    batch_size=batch_size, \n",
    "    temperature=temperature, \n",
    "    use_cosine_similarity=use_cosine_similarity, \n",
    "    alpha_weight=alpha_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d29b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up training components...\n",
      "Training for 100 epochs\n",
      "Optimizer: AdamW with lr=5e-06\n",
      "Scheduler: CosineAnnealingLR\n",
      "Checkpoint directory: ./model/checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Training Setup and Optimizer\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import json\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"Setting up training components...\")\n",
    "OUTPUT_DIR = \"./model\"\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=float(config.get('learning_rate', 5e-6)),\n",
    "    weight_decay=float(config.get('weight_decay', 1e-4))\n",
    ")\n",
    "\n",
    "# Initialize scheduler\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=config.get('epochs', 4000),\n",
    "    eta_min=1e-7\n",
    ")\n",
    "\n",
    "# Training configuration\n",
    "epochs = config.get('epochs', 4000)\n",
    "eval_every_n_epochs = config.get('eval_every_n_epochs', 5)\n",
    "log_every_n_steps = config.get('log_every_n_steps', 2)\n",
    "\n",
    "# Create checkpoint directory\n",
    "checkpoint_dir = os.path.join(OUTPUT_DIR, \"checkpoints\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Training for {epochs} epochs\")\n",
    "print(f\"Optimizer: AdamW with lr={config.get('learning_rate', 5e-6)}\")\n",
    "print(f\"Scheduler: CosineAnnealingLR\")\n",
    "print(f\"Checkpoint directory: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51bd679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Training and Evaluation Functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    batch_losses = []\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch}\")\n",
    "    \n",
    "    for batch_idx, (graphs, mzs, intensities, num_peaks) in enumerate(progress_bar):\n",
    "        # Move data to device\n",
    "        graphs = graphs.to(device)\n",
    "        mzs = mzs.to(device)\n",
    "        intensities = intensities.to(device)\n",
    "        num_peaks = num_peaks.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        mol_features, spec_features = model(graphs, mzs, intensities, num_peaks)\n",
    "        loss = criterion(mol_features, spec_features)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        batch_loss = loss.item()\n",
    "        total_loss += batch_loss\n",
    "        batch_losses.append(batch_loss)\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{batch_loss:.4f}',\n",
    "            'Avg Loss': f'{total_loss/num_batches:.4f}'\n",
    "        })\n",
    "        \n",
    "        # Log every n steps\n",
    "        if batch_idx % log_every_n_steps == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {batch_loss:.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss, batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7149a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_retrieval_metrics(molecular_features, spectral_features):\n",
    "    from sklearn.metrics import pairwise_distances\n",
    "\n",
    "    # Compute cosine distance matrix\n",
    "    distance_matrix = pairwise_distances(molecular_features, spectral_features, metric='cosine')\n",
    "    \n",
    "    # For each molecular feature, find the rank of the correct spectral feature\n",
    "    ranks = []\n",
    "    for i in range(distance_matrix.shape[0]):\n",
    "        sorted_indices = np.argsort(distance_matrix[i])\n",
    "        rank = np.where(sorted_indices == i)[0][0] + 1  # +1 for 1-based rank\n",
    "        ranks.append(rank)\n",
    "    \n",
    "    ranks = np.array(ranks)\n",
    "    \n",
    "    # Compute top-k accuracies\n",
    "    top_1_accuracy = np.mean(ranks <= 1)\n",
    "    top_5_accuracy = np.mean(ranks <= 5)\n",
    "    top_10_accuracy = np.mean(ranks <= 10)\n",
    "    \n",
    "    return {\n",
    "        'top_1_accuracy': top_1_accuracy,\n",
    "        'top_5_accuracy': top_5_accuracy,\n",
    "        'top_10_accuracy': top_10_accuracy\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_model(model, val_loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    molecular_features_list = []\n",
    "    spectral_features_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=f\"Evaluating Epoch {epoch}\")\n",
    "        \n",
    "        for batch_idx, (graphs, mzs, intensities, num_peaks) in enumerate(progress_bar):\n",
    "            # Move data to device\n",
    "            graphs = graphs.to(device)\n",
    "            mzs = mzs.to(device)\n",
    "            intensities = intensities.to(device)\n",
    "            num_peaks = num_peaks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            mol_features, spec_features = model(graphs, mzs, intensities, num_peaks)\n",
    "            loss = criterion(mol_features, spec_features)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Store features for retrieval metrics\n",
    "            molecular_features_list.append(mol_features.cpu().numpy())\n",
    "            spectral_features_list.append(spec_features.cpu().numpy())\n",
    "            \n",
    "            progress_bar.set_postfix({'Val Loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    \n",
    "    # Compute retrieval metrics\n",
    "    all_mol_features = np.vstack(molecular_features_list)\n",
    "    all_spec_features = np.vstack(spectral_features_list)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    cosine_similarities = np.sum(all_mol_features * all_spec_features, axis=1)\n",
    "    mean_similarity = np.mean(cosine_similarities)\n",
    "    \n",
    "    # Compute retrieval metrics\n",
    "    retrieval_metrics = compute_retrieval_metrics(all_mol_features, all_spec_features)\n",
    "    \n",
    "    return avg_loss, mean_similarity, retrieval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "804819b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "def save_checkpoint(model, optimizer, scheduler, epoch, train_loss, val_loss, val_metrics, checkpoint_dir):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'val_metrics': val_metrics,\n",
    "        'config': config\n",
    "    }\n",
    "    \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    # Save best model\n",
    "    best_checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "    if not os.path.exists(best_checkpoint_path):\n",
    "        torch.save(checkpoint, best_checkpoint_path)\n",
    "        print(f\"Best model saved: {best_checkpoint_path}\")\n",
    "    else:\n",
    "        best_checkpoint = torch.load(best_checkpoint_path)\n",
    "        if val_loss < best_checkpoint['val_loss']:\n",
    "            torch.save(checkpoint, best_checkpoint_path)\n",
    "            print(f\"New best model saved: {best_checkpoint_path}\")\n",
    "\n",
    "print(\"Training and evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d49afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   1%|          | 1/107 [00:21<37:11, 21.05s/it, Loss=4.1717, Avg Loss=4.1717]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 4.1717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   3%|▎         | 3/107 [00:22<09:15,  5.34s/it, Loss=4.1893, Avg Loss=4.1826]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 2, Loss: 4.1893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   5%|▍         | 5/107 [00:23<04:09,  2.44s/it, Loss=4.2161, Avg Loss=4.1962]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 4, Loss: 4.2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   7%|▋         | 7/107 [00:25<02:20,  1.40s/it, Loss=4.1766, Avg Loss=4.1927]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 6, Loss: 4.1766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   8%|▊         | 9/107 [00:26<01:47,  1.09s/it, Loss=4.1722, Avg Loss=4.1876]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 8, Loss: 4.1722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  10%|█         | 11/107 [00:28<01:20,  1.19it/s, Loss=4.1773, Avg Loss=4.1874]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss: 4.1773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  12%|█▏        | 13/107 [00:29<01:10,  1.33it/s, Loss=4.1833, Avg Loss=4.1898]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 12, Loss: 4.1833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  14%|█▍        | 15/107 [00:30<01:02,  1.48it/s, Loss=4.1768, Avg Loss=4.1883]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 14, Loss: 4.1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  16%|█▌        | 17/107 [00:32<01:05,  1.37it/s, Loss=4.1671, Avg Loss=4.1861]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 16, Loss: 4.1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  18%|█▊        | 19/107 [00:33<01:04,  1.37it/s, Loss=4.1771, Avg Loss=4.1856]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 18, Loss: 4.1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  20%|█▉        | 21/107 [00:35<01:15,  1.13it/s, Loss=4.1667, Avg Loss=4.1846]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 20, Loss: 4.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  21%|██▏       | 23/107 [00:37<01:04,  1.30it/s, Loss=4.1594, Avg Loss=4.1826]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 22, Loss: 4.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  23%|██▎       | 25/107 [00:38<01:05,  1.25it/s, Loss=4.1792, Avg Loss=4.1823]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 24, Loss: 4.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  25%|██▌       | 27/107 [00:40<01:10,  1.13it/s, Loss=4.1738, Avg Loss=4.1813]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 26, Loss: 4.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  27%|██▋       | 29/107 [00:42<01:02,  1.26it/s, Loss=4.1726, Avg Loss=4.1809]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 28, Loss: 4.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  29%|██▉       | 31/107 [00:43<00:57,  1.31it/s, Loss=4.1603, Avg Loss=4.1799]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 30, Loss: 4.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  31%|███       | 33/107 [00:45<01:02,  1.18it/s, Loss=4.1733, Avg Loss=4.1790]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 32, Loss: 4.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  33%|███▎      | 35/107 [00:47<01:05,  1.10it/s, Loss=4.1632, Avg Loss=4.1784]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 34, Loss: 4.1632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  35%|███▍      | 37/107 [00:48<00:57,  1.22it/s, Loss=4.1477, Avg Loss=4.1773]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 36, Loss: 4.1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  36%|███▋      | 39/107 [00:49<00:50,  1.35it/s, Loss=4.1626, Avg Loss=4.1773]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 38, Loss: 4.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  38%|███▊      | 41/107 [00:51<00:55,  1.20it/s, Loss=4.1398, Avg Loss=4.1759]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 40, Loss: 4.1398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  40%|████      | 43/107 [00:54<01:10,  1.10s/it, Loss=4.1506, Avg Loss=4.1752]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 42, Loss: 4.1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  42%|████▏     | 45/107 [00:56<01:02,  1.01s/it, Loss=4.1643, Avg Loss=4.1747]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 44, Loss: 4.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  44%|████▍     | 47/107 [00:57<00:52,  1.14it/s, Loss=4.1696, Avg Loss=4.1738]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 46, Loss: 4.1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  46%|████▌     | 49/107 [00:59<00:48,  1.19it/s, Loss=4.1601, Avg Loss=4.1736]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 48, Loss: 4.1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  48%|████▊     | 51/107 [01:01<00:46,  1.21it/s, Loss=4.1609, Avg Loss=4.1729]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 50, Loss: 4.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  50%|████▉     | 53/107 [01:03<00:57,  1.06s/it, Loss=4.1530, Avg Loss=4.1722]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 52, Loss: 4.1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  51%|█████▏    | 55/107 [01:10<02:02,  2.36s/it, Loss=4.1792, Avg Loss=4.1724]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 54, Loss: 4.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  53%|█████▎    | 57/107 [01:13<01:34,  1.90s/it, Loss=4.1669, Avg Loss=4.1718]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 56, Loss: 4.1669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  55%|█████▌    | 59/107 [01:15<01:06,  1.38s/it, Loss=4.1585, Avg Loss=4.1715]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 58, Loss: 4.1585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  57%|█████▋    | 61/107 [01:16<00:47,  1.04s/it, Loss=4.1496, Avg Loss=4.1711]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 60, Loss: 4.1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  59%|█████▉    | 63/107 [01:19<00:58,  1.33s/it, Loss=4.1600, Avg Loss=4.1707]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 62, Loss: 4.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  61%|██████    | 65/107 [01:22<01:03,  1.51s/it, Loss=4.1647, Avg Loss=4.1706]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 64, Loss: 4.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  63%|██████▎   | 67/107 [01:29<01:41,  2.54s/it, Loss=4.1538, Avg Loss=4.1702]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 66, Loss: 4.1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  64%|██████▍   | 69/107 [01:31<01:06,  1.74s/it, Loss=4.1609, Avg Loss=4.1695]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 68, Loss: 4.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  66%|██████▋   | 71/107 [01:32<00:43,  1.20s/it, Loss=4.1430, Avg Loss=4.1689]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 70, Loss: 4.1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  68%|██████▊   | 73/107 [01:36<00:58,  1.71s/it, Loss=4.1574, Avg Loss=4.1688]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 72, Loss: 4.1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  70%|███████   | 75/107 [01:39<00:53,  1.67s/it, Loss=4.1612, Avg Loss=4.1684]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 74, Loss: 4.1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  72%|███████▏  | 77/107 [01:42<00:47,  1.58s/it, Loss=4.1582, Avg Loss=4.1681]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 76, Loss: 4.1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  74%|███████▍  | 79/107 [01:48<01:00,  2.17s/it, Loss=4.1520, Avg Loss=4.1679]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 78, Loss: 4.1520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  76%|███████▌  | 81/107 [01:51<00:46,  1.80s/it, Loss=4.1409, Avg Loss=4.1673]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 80, Loss: 4.1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  78%|███████▊  | 83/107 [01:53<00:30,  1.29s/it, Loss=4.1387, Avg Loss=4.1669]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 82, Loss: 4.1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  79%|███████▉  | 85/107 [01:55<00:23,  1.06s/it, Loss=4.1348, Avg Loss=4.1662]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 84, Loss: 4.1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  81%|████████▏ | 87/107 [01:57<00:20,  1.05s/it, Loss=4.1622, Avg Loss=4.1658]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 86, Loss: 4.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  83%|████████▎ | 89/107 [02:02<00:32,  1.78s/it, Loss=4.1475, Avg Loss=4.1654]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 88, Loss: 4.1475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  85%|████████▌ | 91/107 [02:04<00:20,  1.29s/it, Loss=4.1234, Avg Loss=4.1647]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 90, Loss: 4.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  87%|████████▋ | 93/107 [02:11<00:34,  2.49s/it, Loss=4.1661, Avg Loss=4.1645]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 92, Loss: 4.1661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  89%|████████▉ | 95/107 [02:22<00:52,  4.40s/it, Loss=4.1537, Avg Loss=4.1639]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 94, Loss: 4.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  91%|█████████ | 97/107 [02:27<00:34,  3.48s/it, Loss=4.1634, Avg Loss=4.1640]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 96, Loss: 4.1634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  93%|█████████▎| 99/107 [02:29<00:17,  2.22s/it, Loss=4.1380, Avg Loss=4.1634]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 98, Loss: 4.1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  94%|█████████▍| 101/107 [02:34<00:14,  2.44s/it, Loss=4.1512, Avg Loss=4.1631]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 4.1512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  96%|█████████▋| 103/107 [02:37<00:07,  1.84s/it, Loss=4.1559, Avg Loss=4.1627]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 102, Loss: 4.1559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  98%|█████████▊| 105/107 [02:42<00:05,  2.52s/it, Loss=4.1290, Avg Loss=4.1619]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 104, Loss: 4.1290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 107/107 [02:46<00:00,  2.28s/it, Loss=4.1376, Avg Loss=4.1613]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 106, Loss: 4.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 107/107 [02:50<00:00,  1.59s/it, Loss=4.1376, Avg Loss=4.1613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Train Loss: 4.161294, LR: 5.00e-06, Time: 170.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:   1%|          | 1/107 [00:25<45:37, 25.82s/it, Loss=4.1535, Avg Loss=4.1535]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 4.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x118f0c430>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ivangolov/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1476, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/Users/ivangolov/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\", line 67, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 19166) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Cell 17: Training Loop\n",
    "# Training history for plotting\n",
    "train_history = {\n",
    "    'epochs': [],\n",
    "    'train_losses': [],\n",
    "    'val_losses': [],\n",
    "    'val_similarities': [],\n",
    "    'val_top1_acc': [],\n",
    "    'val_top5_acc': [],\n",
    "    'val_top10_acc': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss, batch_losses = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, DEVICE, epoch\n",
    "    )\n",
    "    \n",
    "    # Validation phase (every n epochs)\n",
    "    if epoch % eval_every_n_epochs == 0:\n",
    "        val_loss, val_similarity, val_metrics = evaluate_model(\n",
    "            model, val_loader, criterion, DEVICE, epoch\n",
    "        )\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Log results\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.6f}\")\n",
    "        print(f\"Val Loss: {val_loss:.6f}\")\n",
    "        print(f\"Val Similarity: {val_similarity:.4f}\")\n",
    "        print(f\"Top-1 Accuracy: {val_metrics['top_1_accuracy']:.4f}\")\n",
    "        print(f\"Top-5 Accuracy: {val_metrics['top_5_accuracy']:.4f}\")\n",
    "        print(f\"Top-10 Accuracy: {val_metrics['top_10_accuracy']:.4f}\")\n",
    "        print(f\"Learning Rate: {current_lr:.2e}\")\n",
    "        print(f\"Epoch Time: {epoch_time:.2f}s, Total Time: {total_time:.2f}s\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Store history\n",
    "        train_history['epochs'].append(epoch)\n",
    "        train_history['train_losses'].append(train_loss)\n",
    "        train_history['val_losses'].append(val_loss)\n",
    "        train_history['val_similarities'].append(val_similarity)\n",
    "        train_history['val_top1_acc'].append(val_metrics['top_1_accuracy'])\n",
    "        train_history['val_top5_acc'].append(val_metrics['top_5_accuracy'])\n",
    "        train_history['val_top10_acc'].append(val_metrics['top_10_accuracy'])\n",
    "        train_history['learning_rates'].append(current_lr)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        save_checkpoint(\n",
    "            model, optimizer, scheduler, epoch, \n",
    "            train_loss, val_loss, val_metrics, checkpoint_dir\n",
    "        )\n",
    "        \n",
    "        # Save training history\n",
    "        history_path = os.path.join(OUTPUT_DIR, 'training_history.json')\n",
    "        with open(history_path, 'w') as f:\n",
    "            json.dump(train_history, f, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # Just update learning rate and log basic info\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.6f}, LR: {current_lr:.2e}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Total training time: {(time.time() - start_time)/3600:.2f} hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSU-MS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

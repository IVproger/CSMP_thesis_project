{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3756c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dca8b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load env variables\n",
    "load_dotenv('../../../.env')\n",
    "\n",
    "# Import your model and data loading components\n",
    "from dataloader.dataset_wrapper import create_wrapper_from_dataframe\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c2e974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=3ca7b102c6c8472b9a7638bd224ecfae\n",
      "ClearML results page: https://app.clear.ml/projects/0fec81950d384f0294d2c713df3887db/experiments/3ca7b102c6c8472b9a7638bd224ecfae/output/log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n"
     ]
    }
   ],
   "source": [
    "# First install ClearML if not already installed: pip install clearml\n",
    "import clearml\n",
    "from clearml import Task, Logger\n",
    "\n",
    "# Initialize ClearML Task\n",
    "task = Task.init(project_name='CSMP_thesis_project', task_name='CSMP_traning_phase_1', reuse_last_task_id=False)\n",
    "logger = Logger.current_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44018e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA for GPU acceleration\n",
      "Using device: cuda\n",
      "Validation data path: ../../../data/traning_and_validation/train_deduplicated.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration and paths setup\n",
    "CONFIG_PATH = \"../../../configs/config.yaml\"\n",
    "TRAIN_CSV_PATH = \"../../../data/traning_and_validation/train_deduplicated.csv\"\n",
    "\n",
    "# Device selection \n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "    print(\"Using MPS (Metal Performance Shaders) for GPU acceleration\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "    print(\"Using CUDA for GPU acceleration\")\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Validation data path: {TRAIN_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502b6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration...\n",
      "Configuration loaded:\n",
      "- Batch size: 256\n",
      "- Model config keys: []\n",
      "- Loss config: {'temperature': 0.1, 'use_cosine_similarity': True, 'alpha_weight': 0.75}\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load configuration\n",
    "print(\"Loading configuration...\")\n",
    "config = yaml.load(open(CONFIG_PATH, \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Batch size: {config.get('batch_size', 64)}\")\n",
    "print(f\"- Model config keys: {list(config.get('model', {}).keys())}\")\n",
    "print(f\"- Loss config: {config.get('loss', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e06fc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 256,\n",
       " 'epochs': 10,\n",
       " 'eval_every_n_epochs': 2,\n",
       " 'log_every_n_steps': 2,\n",
       " 'learning_rate': '1e-06',\n",
       " 'weight_decay': 0.0001,\n",
       " 'fp16_precision': True,\n",
       " 'truncation': True,\n",
       " 'model_config': {'emb_dim': 256,\n",
       "  'spec_embed_dim': 256,\n",
       "  'embed_dim': 128,\n",
       "  'feat_dim': 512,\n",
       "  'num_layer': 5,\n",
       "  'layers': 5,\n",
       "  'drop_ratio': 0.1,\n",
       "  'dropout': 0.1,\n",
       "  'pool': 'mean'},\n",
       " 'dataset': {'s': 1,\n",
       "  'num_workers': 0,\n",
       "  'valid_size': 0.1,\n",
       "  'ms2_file': '/home/xieting/graph_transformer_esa_hpc/data/qotf_20.mgf',\n",
       "  'smi_file': '/home/xieting/graph_transformer_esa_hpc/data/smi_qtof_20.npy'},\n",
       " 'loss': {'temperature': 0.1,\n",
       "  'use_cosine_similarity': True,\n",
       "  'alpha_weight': 0.75}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.connect(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbfbadd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "Validation dataset shape: (798444, 10)\n",
      "Columns: ['peaks_json', 'ion_source', 'compound_source', 'instrument', 'adduct', 'precursor_mz', 'smiles', 'inchikey', 'ion_mode', 'molecular_formula']\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peaks_json</th>\n",
       "      <th>ion_source</th>\n",
       "      <th>compound_source</th>\n",
       "      <th>instrument</th>\n",
       "      <th>adduct</th>\n",
       "      <th>precursor_mz</th>\n",
       "      <th>smiles</th>\n",
       "      <th>inchikey</th>\n",
       "      <th>ion_mode</th>\n",
       "      <th>molecular_formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[42.014248, 0.10199999999999998], [42.26601, ...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[49.01717, 0.155], [49.020023, 0.253], [67.05...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[49.017338, 0.242], [49.020237, 0.181], [67.0...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[49.01701, 0.144], [49.019947, 0.244], [139.0...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[49.017166, 0.155], [49.020008, 0.253], [139....</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          peaks_json ion_source  \\\n",
       "0  [[42.014248, 0.10199999999999998], [42.26601, ...        ESI   \n",
       "1  [[49.01717, 0.155], [49.020023, 0.253], [67.05...        ESI   \n",
       "2  [[49.017338, 0.242], [49.020237, 0.181], [67.0...        ESI   \n",
       "3  [[49.01701, 0.144], [49.019947, 0.244], [139.0...        ESI   \n",
       "4  [[49.017166, 0.155], [49.020008, 0.253], [139....        ESI   \n",
       "\n",
       "  compound_source instrument  adduct  precursor_mz  \\\n",
       "0           Crude   Orbitrap  [M+H]+       377.186   \n",
       "1           Crude   Orbitrap  [M+H]+       377.186   \n",
       "2           Crude   Orbitrap  [M+H]+       377.186   \n",
       "3           Crude   Orbitrap  [M+H]+       377.186   \n",
       "4           Crude   Orbitrap  [M+H]+       377.186   \n",
       "\n",
       "                                              smiles  \\\n",
       "0  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "1  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "2  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "3  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "4  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "\n",
       "                      inchikey  ion_mode molecular_formula  \n",
       "0  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "1  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "2  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "3  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "4  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Load and explore validation data\n",
    "print(\"Loading train data...\")\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "\n",
    "print(f\"Validation dataset shape: {df_train.shape}\")\n",
    "print(f\"Columns: {list(df_train.columns)}\")\n",
    "print(f\"Sample data:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da40ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample = df_train.sample(n=10000,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed921164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data loaders\n",
      "Converting DataFrame to compatible files...\n",
      "Processed 10000 valid spectra out of 10000 total entries.\n",
      "Create data wrapper\n",
      "calculating molecular graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 513/8000 [00:00<00:11, 629.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 901/8000 [00:01<00:12, 588.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C(O)C=1C=CC=CC1C=2C=3C=CC(=CC3OC4=CC(C=CC42)=[N+](CC)CC)N(CC)CC calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1347/8000 [00:02<00:10, 623.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=C(CCCCCCCCCCC)CC(O)S(=O)(=O)[O-] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1666/8000 [00:02<00:10, 626.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C(=COC2=C1C=C(C(O)=C2C[NH+](C)C)CC)C=3C=CC=4OCCOC4C3 calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2243/8000 [00:03<00:08, 640.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C=2C=C(C(O)=C(C2OC(=C1C=3C=CC=4OCCOC4C3)C)C[NH+](C)C)CCC calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3018/8000 [00:04<00:07, 628.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C2=CC=C(O)C(=C2OC(=C1C=3C=CC=4OCCCOC4C3)C)C[NH+](C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3147/8000 [00:05<00:07, 634.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=P([O-])(O)OCC1OC(N2C=NC=3C(=NC=NC32)N)C(O)C1O calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 3591/8000 [00:05<00:07, 626.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C2=CC=C(O)C(=C2OC(=C1C=3C=CC=4OCCCOC4C3)C)C[NH+](C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 4162/8000 [00:06<00:06, 628.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n",
      "SMILES [Cl-].OC=1C=C(O)C=2C=C(OC3OC(CO)C(O)C(O)C3O)C(=[O+]C2C1)C=4C=CC(O)=C(O)C4 calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 4614/8000 [00:07<00:05, 629.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=C(CCCCCCCCCCC)CC(O)S(=O)(=O)[O-] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 4936/8000 [00:08<00:04, 627.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES CCC1=C(C2=NC1=CC3=C(C4=C([N-]3)C(=C5[C@H]([C@@H](C(=N5)C=C6C(=C(C(=C2)[N-]6)C=C)C)C)CCC(=O)OC/C=C(\\C)/CCC[C@H](C)CCC[C@H](C)CCCC(C)C)[C@H](C4=O)C(=O)OC)C)C=O.[Mg+2] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 5125/8000 [00:08<00:04, 620.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 5570/8000 [00:09<00:03, 620.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES C1C(N(C2=C(N1)N=C(NC2=O)N)C=O)CNC3=CC=C(C=C3)C(=O)N[C@@H](CCC(=O)[O-])C(=O)[O-].[Ca+2] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 6140/8000 [00:09<00:02, 629.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=C([O-])C(CC)C1OC(C(=CC=CC2C=CC3CCCC3C2C(=O)C4=CC=CN4)CC)C(C)CC1 calculation failure\n",
      "SMILES [K+].[K+].O=C([O-])C1OC(OC2C(OC(C(=O)[O-])C(O)C2O)OC3CCC4(C)C5C(=O)C=C6C7CC(C(=O)O)(C)CCC7(C)CCC6(C)C5(C)CCC4C3(C)C)C(O)C(O)C1O calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 7104/8000 [00:11<00:01, 626.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [K+].O=C([O-])C12CCC(C(=C)C)C2C3CCC4C5(C)CCC(=O)C(C)(C)C5CCC4(C)C3(C)CC1 calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:12<00:00, 618.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 6875 molecular graph-mass spectrometry pairs\n",
      "calculating molecular graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 66/2000 [00:00<00:02, 657.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=C(CCCCCCCCCCC)CC(O)S(=O)(=O)[O-] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 324/2000 [00:00<00:02, 629.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Br-].O=C(OC1CC2C3OC3C(C1)[N+]2(C)CCCC)C(C=4C=CC=CC4)CO calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 646/2000 [00:01<00:02, 631.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n",
      "SMILES [K+].O=S(=O)([O-])ON=C(SC1OC(CO)C(O)C(O)C1O)CC=C.O calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 914/2000 [00:01<00:01, 634.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].OC=1C=C(O)C=2C=C(OC3OC(CO)C(O)C(O)C3O)C(=[O+]C2C1)C=4C=CC(O)=C(O)C4 calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 1373/2000 [00:02<00:01, 620.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C2=CC=C(O)C(=C2OC(=C1C=3C=CC=4OCCCOC4C3)C)C[NH+](C)C calculation failure\n",
      "SMILES [K+].O=S(=O)([O-])ON=C(SC1OC(CO)C(O)C(O)C1O)CC=C.O calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:03<00:00, 633.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 1697 molecular graph-mass spectrometry pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Prepare validation data loader\n",
    "print(\"Preparing data loaders\")\n",
    "\n",
    "# Create data wrapper from DataFrame\n",
    "wrapper = create_wrapper_from_dataframe(\n",
    "    df=df_train_sample,\n",
    "    batch_size=config.get('batch_size'),  \n",
    "    num_workers=8,\n",
    "    valid_size=config.get('valid_size'),  \n",
    "    use_ddp=False,\n",
    "    output_dir=\"../../../data/train_feature/\",\n",
    "    recompute=True\n",
    ")\n",
    "\n",
    "# Get the data loader\n",
    "train_loader, val_loader = wrapper.get_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d777a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ModelCLR\n",
    "\n",
    "# Initialize model architecture\n",
    "model = ModelCLR(**config[\"model_config\"]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc0c56bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelCLR(\n",
       "  (Smiles_model): SmilesModel(\n",
       "    (x_embedding1): Embedding(119, 256)\n",
       "    (x_embedding2): Embedding(4, 256)\n",
       "    (x_embedding3): Embedding(8, 256)\n",
       "    (x_embedding4): Embedding(6, 256)\n",
       "    (x_embedding5): Embedding(5, 256)\n",
       "    (gnns): ModuleList(\n",
       "      (0-4): 5 x GINEConv()\n",
       "    )\n",
       "    (batch_norms): ModuleList(\n",
       "      (0-4): 5 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (feat_lin): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (out_lin): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (MS_model): MSModel(\n",
       "    (mz_embedder): FourierEmbedder()\n",
       "    (input_compress): Linear(in_features=257, out_features=256, bias=True)\n",
       "    (peak_attn_layers): ModuleList(\n",
       "      (0-4): 5 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (pooling_layer): AdaptiveAvgPool1d(output_size=1)\n",
       "    (output_layer): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (smi_esa): ESA_SMILES(\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (spec_esa): ESA_SPEC(\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (smi_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (spec_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eab11f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ANALYSIS:\n",
      "----------------------------------------\n",
      "Trainable Parameters: 6,102,784\n"
     ]
    }
   ],
   "source": [
    "# Parameter Count\n",
    "print(\"PARAMETER ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3e1bd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY ANALYSIS:\n",
      "----------------------------------------\n",
      "Model Size: 23.29 MB\n",
      "Parameter Memory: 23.28 MB\n",
      "Buffer Memory: 0.01 MB\n"
     ]
    }
   ],
   "source": [
    "# Memory Usage (approximate)\n",
    "print(\"MEMORY ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "model_size_mb = (param_size + buffer_size) / 1024 / 1024\n",
    "\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"Parameter Memory: {param_size / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Buffer Memory: {buffer_size / 1024 / 1024:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f9e6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss.nt_xent import NTXentLoss\n",
    "\n",
    "# Initialize loss function\n",
    "temperature = config.get('loss', {}).get('temperature', 0.1)\n",
    "batch_size = config.get('batch_size', 512)\n",
    "use_cosine_similarity = config.get('loss', {}).get('use_cosine_similarity', True)\n",
    "alpha_weight = config.get('loss', {}).get('alpha_weight', 1.0)\n",
    "\n",
    "criterion = NTXentLoss(\n",
    "    device=DEVICE, \n",
    "    batch_size=batch_size, \n",
    "    temperature=temperature, \n",
    "    use_cosine_similarity=use_cosine_similarity, \n",
    "    alpha_weight=alpha_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca14bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up training components...\n",
      "Training for 10 epochs\n",
      "Optimizer: AdamW with lr=1e-06\n",
      "Checkpoint directory: ../../../models/models_experiments/candidate_v1/checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Training Setup and Optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"Setting up training components...\")\n",
    "OUTPUT_DIR = \"../../../models/models_experiments/candidate_v1\"\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=float(config.get('learning_rate', 5e-6)),\n",
    "    weight_decay=float(config.get('weight_decay', 1e-4))\n",
    ")\n",
    "\n",
    "# Training configuration\n",
    "epochs = config.get('epochs', 100)\n",
    "eval_every_n_epochs = config.get('eval_every_n_epochs', 5)\n",
    "log_every_n_steps = config.get('log_every_n_steps', 2)\n",
    "\n",
    "# Create checkpoint directory\n",
    "checkpoint_dir = os.path.join(OUTPUT_DIR, \"checkpoints\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Training for {epochs} epochs\")\n",
    "print(f\"Optimizer: AdamW with lr={config.get('learning_rate', 5e-6)}\")\n",
    "print(f\"Checkpoint directory: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2270602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Training and Evaluation Functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    batch_losses = []\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch}\")\n",
    "    \n",
    "    for batch_idx, (graphs, mzs, intensities, num_peaks) in enumerate(progress_bar):\n",
    "        \n",
    "        # Move data to device\n",
    "        graphs = graphs.to(device)\n",
    "        mzs = mzs.to(device)\n",
    "        intensities = intensities.to(device)\n",
    "        num_peaks = num_peaks.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        mol_features, spec_features = model(graphs, mzs, intensities, num_peaks)\n",
    "        loss = criterion(mol_features, spec_features)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        batch_loss = loss.item()\n",
    "        total_loss += batch_loss\n",
    "        batch_losses.append(batch_loss)\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{batch_loss:.4f}',\n",
    "            'Avg Loss': f'{total_loss/num_batches:.4f}'\n",
    "        })\n",
    "        \n",
    "        # Log every n steps\n",
    "        if batch_idx % log_every_n_steps == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {batch_loss:.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss, batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dadfa2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    molecular_features_list = []\n",
    "    spectral_features_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=f\"Evaluating Epoch {epoch}\")\n",
    "        \n",
    "        for batch_idx, (graphs, mzs, intensities, num_peaks) in enumerate(progress_bar):\n",
    "            # Move data to device\n",
    "            graphs = graphs.to(device)\n",
    "            mzs = mzs.to(device)\n",
    "            intensities = intensities.to(device)\n",
    "            num_peaks = num_peaks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            mol_features, spec_features = model(graphs, mzs, intensities, num_peaks)\n",
    "            loss = criterion(mol_features, spec_features)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Store features for retrieval metrics\n",
    "            molecular_features_list.append(mol_features.cpu().numpy())\n",
    "            spectral_features_list.append(spec_features.cpu().numpy())\n",
    "            \n",
    "            progress_bar.set_postfix({'Val Loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    \n",
    "    # Compute retrieval metrics\n",
    "    all_mol_features = np.vstack(molecular_features_list)\n",
    "    all_spec_features = np.vstack(spectral_features_list)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    cosine_similarities = np.sum(all_mol_features * all_spec_features, axis=1)\n",
    "    mean_similarity = np.mean(cosine_similarities)\n",
    "        \n",
    "    return avg_loss, mean_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df13de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, train_loss, val_loss, checkpoint_dir):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'config': config\n",
    "    }\n",
    "    \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    # Save best model\n",
    "    best_checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "    if not os.path.exists(best_checkpoint_path):\n",
    "        torch.save(checkpoint, best_checkpoint_path)\n",
    "        print(f\"Best model saved: {best_checkpoint_path}\")\n",
    "    else:\n",
    "        best_checkpoint = torch.load(best_checkpoint_path)\n",
    "        if val_loss < best_checkpoint['val_loss']:\n",
    "            torch.save(checkpoint, best_checkpoint_path)\n",
    "            print(f\"New best model saved: {best_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7034d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   4%|▍         | 1/26 [00:00<00:23,  1.07it/s, Loss=5.6384, Avg Loss=5.6384]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 5.6384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  12%|█▏        | 3/26 [00:01<00:11,  2.09it/s, Loss=5.6191, Avg Loss=5.6229]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 2, Loss: 5.6191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  19%|█▉        | 5/26 [00:02<00:07,  2.95it/s, Loss=5.6001, Avg Loss=5.6147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 4, Loss: 5.6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  27%|██▋       | 7/26 [00:02<00:05,  3.18it/s, Loss=5.5955, Avg Loss=5.6103]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 6, Loss: 5.5955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  35%|███▍      | 9/26 [00:03<00:05,  3.11it/s, Loss=5.6143, Avg Loss=5.6091]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 8, Loss: 5.6143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  42%|████▏     | 11/26 [00:04<00:05,  2.98it/s, Loss=5.5900, Avg Loss=5.6059]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss: 5.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  50%|█████     | 13/26 [00:04<00:03,  3.48it/s, Loss=5.6076, Avg Loss=5.6057]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 12, Loss: 5.6076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  58%|█████▊    | 15/26 [00:05<00:03,  3.47it/s, Loss=5.6014, Avg Loss=5.6046]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 14, Loss: 5.6014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  65%|██████▌   | 17/26 [00:05<00:02,  3.64it/s, Loss=5.5829, Avg Loss=5.6030]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 16, Loss: 5.5829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  73%|███████▎  | 19/26 [00:06<00:02,  3.40it/s, Loss=5.5833, Avg Loss=5.6014]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 18, Loss: 5.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  81%|████████  | 21/26 [00:06<00:01,  3.31it/s, Loss=5.5810, Avg Loss=5.6003]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 20, Loss: 5.5810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  88%|████████▊ | 23/26 [00:07<00:00,  3.34it/s, Loss=5.5990, Avg Loss=5.5999]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 22, Loss: 5.5990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  96%|█████████▌| 25/26 [00:08<00:00,  3.24it/s, Loss=5.5898, Avg Loss=5.5986]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 24, Loss: 5.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 26/26 [00:08<00:00,  3.07it/s, Loss=5.5890, Avg Loss=5.5982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 5.598230, LR: 1.00e-06, Time: 8.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:   4%|▍         | 1/26 [00:00<00:14,  1.67it/s, Loss=5.5798, Avg Loss=5.5798]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 5.5798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  12%|█▏        | 3/26 [00:01<00:09,  2.47it/s, Loss=5.6007, Avg Loss=5.5830]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 2, Loss: 5.6007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  19%|█▉        | 5/26 [00:01<00:06,  3.22it/s, Loss=5.5816, Avg Loss=5.5829]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 4, Loss: 5.5816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  27%|██▋       | 7/26 [00:02<00:05,  3.27it/s, Loss=5.5678, Avg Loss=5.5801]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 6, Loss: 5.5678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  35%|███▍      | 9/26 [00:03<00:05,  3.25it/s, Loss=5.5833, Avg Loss=5.5814]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 8, Loss: 5.5833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  42%|████▏     | 11/26 [00:03<00:04,  3.03it/s, Loss=5.5773, Avg Loss=5.5806]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 10, Loss: 5.5773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  50%|█████     | 13/26 [00:04<00:03,  3.51it/s, Loss=5.5804, Avg Loss=5.5803]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 12, Loss: 5.5804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  58%|█████▊    | 15/26 [00:04<00:03,  3.48it/s, Loss=5.5816, Avg Loss=5.5804]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 14, Loss: 5.5816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  65%|██████▌   | 17/26 [00:05<00:02,  3.67it/s, Loss=5.5722, Avg Loss=5.5801]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 16, Loss: 5.5722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  73%|███████▎  | 19/26 [00:05<00:02,  3.40it/s, Loss=5.5729, Avg Loss=5.5800]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 18, Loss: 5.5729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  81%|████████  | 21/26 [00:06<00:01,  3.27it/s, Loss=5.5785, Avg Loss=5.5801]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 20, Loss: 5.5785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  88%|████████▊ | 23/26 [00:07<00:00,  3.32it/s, Loss=5.5987, Avg Loss=5.5810]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 22, Loss: 5.5987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  96%|█████████▌| 25/26 [00:07<00:00,  3.24it/s, Loss=5.5867, Avg Loss=5.5808]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 24, Loss: 5.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 26/26 [00:08<00:00,  3.19it/s, Loss=5.5798, Avg Loss=5.5807]\n",
      "Evaluating Epoch 2: 100%|██████████| 7/7 [00:01<00:00,  5.58it/s, Val Loss=5.1014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "Train Loss: 5.580743\n",
      "Val Loss: 5.498726\n",
      "Val mean similarity: -0.0902\n",
      "Learning Rate: 1.00e-06\n",
      "Epoch Time: 9.42s, Total Time: 17.89s\n",
      "------------------------------------------------------------\n",
      "Checkpoint saved: ../../../models/models_experiments/candidate_v1/checkpoints/checkpoint_epoch_2.pth\n",
      "Best model saved: ../../../models/models_experiments/candidate_v1/checkpoints/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:   4%|▍         | 1/26 [00:00<00:14,  1.70it/s, Loss=5.5821, Avg Loss=5.5821]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 5.5821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  12%|█▏        | 3/26 [00:01<00:09,  2.45it/s, Loss=5.5819, Avg Loss=5.5792]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 2, Loss: 5.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  19%|█▉        | 5/26 [00:01<00:06,  3.15it/s, Loss=5.5743, Avg Loss=5.5786]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 4, Loss: 5.5743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  27%|██▋       | 7/26 [00:02<00:05,  3.23it/s, Loss=5.5705, Avg Loss=5.5777]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 6, Loss: 5.5705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  35%|███▍      | 9/26 [00:03<00:05,  3.26it/s, Loss=5.5766, Avg Loss=5.5772]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 8, Loss: 5.5766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  42%|████▏     | 11/26 [00:03<00:04,  3.02it/s, Loss=5.5686, Avg Loss=5.5756]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 10, Loss: 5.5686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  50%|█████     | 13/26 [00:04<00:03,  3.48it/s, Loss=5.5723, Avg Loss=5.5754]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 12, Loss: 5.5723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  58%|█████▊    | 15/26 [00:04<00:03,  3.47it/s, Loss=5.5714, Avg Loss=5.5747]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 14, Loss: 5.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  65%|██████▌   | 17/26 [00:05<00:02,  3.66it/s, Loss=5.5769, Avg Loss=5.5747]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 16, Loss: 5.5769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  73%|███████▎  | 19/26 [00:05<00:02,  3.40it/s, Loss=5.5679, Avg Loss=5.5736]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 18, Loss: 5.5679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  81%|████████  | 21/26 [00:06<00:01,  3.31it/s, Loss=5.5778, Avg Loss=5.5738]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 20, Loss: 5.5778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  88%|████████▊ | 23/26 [00:07<00:00,  3.35it/s, Loss=5.5759, Avg Loss=5.5737]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 22, Loss: 5.5759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  96%|█████████▌| 25/26 [00:07<00:00,  3.27it/s, Loss=5.5779, Avg Loss=5.5735]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 24, Loss: 5.5779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 26/26 [00:08<00:00,  3.18it/s, Loss=5.5667, Avg Loss=5.5733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train Loss: 5.573266, LR: 1.00e-06, Time: 8.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:   4%|▍         | 1/26 [00:00<00:16,  1.55it/s, Loss=5.5773, Avg Loss=5.5773]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 0, Loss: 5.5773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  12%|█▏        | 3/26 [00:01<00:09,  2.39it/s, Loss=5.5763, Avg Loss=5.5717]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 2, Loss: 5.5763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  19%|█▉        | 5/26 [00:01<00:06,  3.12it/s, Loss=5.5629, Avg Loss=5.5674]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 4, Loss: 5.5629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  27%|██▋       | 7/26 [00:02<00:05,  3.17it/s, Loss=5.5595, Avg Loss=5.5665]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 6, Loss: 5.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  35%|███▍      | 9/26 [00:03<00:05,  3.23it/s, Loss=5.5761, Avg Loss=5.5669]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 8, Loss: 5.5761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  42%|████▏     | 11/26 [00:03<00:04,  3.02it/s, Loss=5.5578, Avg Loss=5.5660]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 10, Loss: 5.5578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  50%|█████     | 13/26 [00:04<00:03,  3.46it/s, Loss=5.5599, Avg Loss=5.5661]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 12, Loss: 5.5599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  58%|█████▊    | 15/26 [00:04<00:03,  3.42it/s, Loss=5.5688, Avg Loss=5.5663]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 14, Loss: 5.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  65%|██████▌   | 17/26 [00:05<00:02,  3.63it/s, Loss=5.5657, Avg Loss=5.5667]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 16, Loss: 5.5657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  73%|███████▎  | 19/26 [00:06<00:02,  3.39it/s, Loss=5.5540, Avg Loss=5.5658]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 18, Loss: 5.5540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  81%|████████  | 21/26 [00:06<00:01,  3.30it/s, Loss=5.5657, Avg Loss=5.5655]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 20, Loss: 5.5657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  88%|████████▊ | 23/26 [00:07<00:00,  3.35it/s, Loss=5.5714, Avg Loss=5.5658]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 22, Loss: 5.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  96%|█████████▌| 25/26 [00:07<00:00,  3.26it/s, Loss=5.5677, Avg Loss=5.5656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 24, Loss: 5.5677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 26/26 [00:08<00:00,  3.16it/s, Loss=5.5675, Avg Loss=5.5657]\n",
      "Evaluating Epoch 4: 100%|██████████| 7/7 [00:01<00:00,  5.53it/s, Val Loss=5.0908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n",
      "Train Loss: 5.565673\n",
      "Val Loss: 5.489662\n",
      "Val mean similarity: -0.0063\n",
      "Learning Rate: 1.00e-06\n",
      "Epoch Time: 9.50s, Total Time: 49.27s\n",
      "------------------------------------------------------------\n",
      "Checkpoint saved: ../../../models/models_experiments/candidate_v1/checkpoints/checkpoint_epoch_4.pth\n",
      "New best model saved: ../../../models/models_experiments/candidate_v1/checkpoints/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:   4%|▍         | 1/26 [00:00<00:15,  1.62it/s, Loss=5.5691, Avg Loss=5.5691]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 0, Loss: 5.5691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  12%|█▏        | 3/26 [00:01<00:09,  2.45it/s, Loss=5.5663, Avg Loss=5.5655]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 2, Loss: 5.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  19%|█▉        | 5/26 [00:01<00:06,  3.17it/s, Loss=5.5570, Avg Loss=5.5637]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 4, Loss: 5.5570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  27%|██▋       | 7/26 [00:02<00:05,  3.24it/s, Loss=5.5635, Avg Loss=5.5639]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 6, Loss: 5.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  35%|███▍      | 9/26 [00:03<00:05,  3.27it/s, Loss=5.5726, Avg Loss=5.5655]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 8, Loss: 5.5726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  42%|████▏     | 11/26 [00:03<00:04,  3.04it/s, Loss=5.5591, Avg Loss=5.5648]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 10, Loss: 5.5591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  50%|█████     | 13/26 [00:04<00:03,  3.47it/s, Loss=5.5614, Avg Loss=5.5639]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 12, Loss: 5.5614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  58%|█████▊    | 15/26 [00:04<00:03,  3.44it/s, Loss=5.5617, Avg Loss=5.5641]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 14, Loss: 5.5617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  65%|██████▌   | 17/26 [00:05<00:02,  3.63it/s, Loss=5.5612, Avg Loss=5.5640]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 16, Loss: 5.5612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  73%|███████▎  | 19/26 [00:05<00:02,  3.39it/s, Loss=5.5606, Avg Loss=5.5636]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 18, Loss: 5.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  81%|████████  | 21/26 [00:06<00:01,  3.30it/s, Loss=5.5714, Avg Loss=5.5640]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 20, Loss: 5.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  88%|████████▊ | 23/26 [00:07<00:00,  3.33it/s, Loss=5.5689, Avg Loss=5.5640]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 22, Loss: 5.5689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  96%|█████████▌| 25/26 [00:07<00:00,  3.24it/s, Loss=5.5641, Avg Loss=5.5638]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 24, Loss: 5.5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 26/26 [00:08<00:00,  3.18it/s, Loss=5.5596, Avg Loss=5.5636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 5.563597, LR: 1.00e-06, Time: 8.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:   4%|▍         | 1/26 [00:00<00:14,  1.70it/s, Loss=5.5693, Avg Loss=5.5693]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 0, Loss: 5.5693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  12%|█▏        | 3/26 [00:01<00:09,  2.35it/s, Loss=5.5654, Avg Loss=5.5649]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 2, Loss: 5.5654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  19%|█▉        | 5/26 [00:01<00:06,  3.07it/s, Loss=5.5568, Avg Loss=5.5630]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 4, Loss: 5.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  27%|██▋       | 7/26 [00:02<00:05,  3.18it/s, Loss=5.5560, Avg Loss=5.5628]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 6, Loss: 5.5560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  35%|███▍      | 9/26 [00:03<00:05,  3.25it/s, Loss=5.5649, Avg Loss=5.5625]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 8, Loss: 5.5649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  42%|████▏     | 11/26 [00:03<00:04,  3.00it/s, Loss=5.5509, Avg Loss=5.5612]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 10, Loss: 5.5509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  50%|█████     | 13/26 [00:04<00:03,  3.49it/s, Loss=5.5605, Avg Loss=5.5617]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 12, Loss: 5.5605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  58%|█████▊    | 15/26 [00:04<00:03,  3.47it/s, Loss=5.5603, Avg Loss=5.5618]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 14, Loss: 5.5603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  65%|██████▌   | 17/26 [00:05<00:02,  3.66it/s, Loss=5.5524, Avg Loss=5.5616]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 16, Loss: 5.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  73%|███████▎  | 19/26 [00:06<00:02,  3.40it/s, Loss=5.5541, Avg Loss=5.5609]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 18, Loss: 5.5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  81%|████████  | 21/26 [00:06<00:01,  3.31it/s, Loss=5.5655, Avg Loss=5.5609]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 20, Loss: 5.5655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  88%|████████▊ | 23/26 [00:07<00:00,  3.34it/s, Loss=5.5614, Avg Loss=5.5608]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 22, Loss: 5.5614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  96%|█████████▌| 25/26 [00:07<00:00,  3.26it/s, Loss=5.5645, Avg Loss=5.5609]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 24, Loss: 5.5645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 26/26 [00:08<00:00,  3.16it/s, Loss=5.5525, Avg Loss=5.5606]\n",
      "Evaluating Epoch 6: 100%|██████████| 7/7 [00:01<00:00,  5.18it/s, Val Loss=5.0877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n",
      "Train Loss: 5.560579\n",
      "Val Loss: 5.486757\n",
      "Val mean similarity: -0.0350\n",
      "Learning Rate: 1.00e-06\n",
      "Epoch Time: 9.59s, Total Time: 87.62s\n",
      "------------------------------------------------------------\n",
      "Checkpoint saved: ../../../models/models_experiments/candidate_v1/checkpoints/checkpoint_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connecting multiple input models with the same name: `best_model`. This might result in the wrong model being used when executing remotely\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved: ../../../models/models_experiments/candidate_v1/checkpoints/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:   4%|▍         | 1/26 [00:00<00:14,  1.76it/s, Loss=5.5598, Avg Loss=5.5598]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 0, Loss: 5.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  12%|█▏        | 3/26 [00:01<00:09,  2.45it/s, Loss=5.5645, Avg Loss=5.5597]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 2, Loss: 5.5645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  19%|█▉        | 5/26 [00:01<00:06,  3.18it/s, Loss=5.5549, Avg Loss=5.5592]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 4, Loss: 5.5549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  27%|██▋       | 7/26 [00:02<00:05,  3.25it/s, Loss=5.5589, Avg Loss=5.5593]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 6, Loss: 5.5589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  35%|███▍      | 9/26 [00:03<00:05,  3.27it/s, Loss=5.5635, Avg Loss=5.5588]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 8, Loss: 5.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  42%|████▏     | 11/26 [00:03<00:05,  2.97it/s, Loss=5.5496, Avg Loss=5.5579]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 10, Loss: 5.5496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  50%|█████     | 13/26 [00:04<00:03,  3.45it/s, Loss=5.5578, Avg Loss=5.5584]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 12, Loss: 5.5578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  58%|█████▊    | 15/26 [00:04<00:03,  3.44it/s, Loss=5.5600, Avg Loss=5.5589]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 14, Loss: 5.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  65%|██████▌   | 17/26 [00:05<00:02,  3.63it/s, Loss=5.5573, Avg Loss=5.5591]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 16, Loss: 5.5573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  73%|███████▎  | 19/26 [00:05<00:02,  3.37it/s, Loss=5.5576, Avg Loss=5.5589]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 18, Loss: 5.5576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  81%|████████  | 21/26 [00:06<00:01,  3.28it/s, Loss=5.5551, Avg Loss=5.5585]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 20, Loss: 5.5551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  88%|████████▊ | 23/26 [00:07<00:00,  3.32it/s, Loss=5.5593, Avg Loss=5.5587]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 22, Loss: 5.5593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  96%|█████████▌| 25/26 [00:07<00:00,  3.24it/s, Loss=5.5647, Avg Loss=5.5588]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 24, Loss: 5.5647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 26/26 [00:08<00:00,  3.16it/s, Loss=5.5562, Avg Loss=5.5587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Train Loss: 5.558659, LR: 1.00e-06, Time: 8.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:   4%|▍         | 1/26 [00:00<00:17,  1.39it/s, Loss=5.5544, Avg Loss=5.5544]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 0, Loss: 5.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  12%|█▏        | 3/26 [00:01<00:10,  2.27it/s, Loss=5.5595, Avg Loss=5.5561]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 2, Loss: 5.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  19%|█▉        | 5/26 [00:01<00:06,  3.04it/s, Loss=5.5606, Avg Loss=5.5583]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 4, Loss: 5.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  27%|██▋       | 7/26 [00:02<00:06,  3.15it/s, Loss=5.5588, Avg Loss=5.5579]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 6, Loss: 5.5588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  35%|███▍      | 9/26 [00:03<00:05,  3.21it/s, Loss=5.5620, Avg Loss=5.5583]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 8, Loss: 5.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  42%|████▏     | 11/26 [00:03<00:04,  3.00it/s, Loss=5.5517, Avg Loss=5.5576]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 10, Loss: 5.5517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  50%|█████     | 13/26 [00:04<00:03,  3.48it/s, Loss=5.5514, Avg Loss=5.5577]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 12, Loss: 5.5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  58%|█████▊    | 15/26 [00:04<00:03,  3.44it/s, Loss=5.5559, Avg Loss=5.5577]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 14, Loss: 5.5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  65%|██████▌   | 17/26 [00:05<00:02,  3.62it/s, Loss=5.5511, Avg Loss=5.5577]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 16, Loss: 5.5511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  73%|███████▎  | 19/26 [00:06<00:02,  3.37it/s, Loss=5.5536, Avg Loss=5.5576]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 18, Loss: 5.5536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  81%|████████  | 21/26 [00:06<00:01,  3.28it/s, Loss=5.5518, Avg Loss=5.5570]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 20, Loss: 5.5518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  88%|████████▊ | 23/26 [00:07<00:00,  3.31it/s, Loss=5.5665, Avg Loss=5.5572]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 22, Loss: 5.5665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  96%|█████████▌| 25/26 [00:08<00:00,  3.22it/s, Loss=5.5558, Avg Loss=5.5568]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 24, Loss: 5.5558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 26/26 [00:08<00:00,  3.11it/s, Loss=5.5569, Avg Loss=5.5568]\n",
      "Evaluating Epoch 8: 100%|██████████| 7/7 [00:01<00:00,  5.63it/s, Val Loss=5.0859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n",
      "Train Loss: 5.556778\n",
      "Val Loss: 5.485030\n",
      "Val mean similarity: -0.0447\n",
      "Learning Rate: 1.00e-06\n",
      "Epoch Time: 9.62s, Total Time: 125.94s\n",
      "------------------------------------------------------------\n",
      "Checkpoint saved: ../../../models/models_experiments/candidate_v1/checkpoints/checkpoint_epoch_8.pth\n",
      "New best model saved: ../../../models/models_experiments/candidate_v1/checkpoints/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:   4%|▍         | 1/26 [00:00<00:15,  1.65it/s, Loss=5.5595, Avg Loss=5.5595]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 0, Loss: 5.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  12%|█▏        | 3/26 [00:01<00:09,  2.47it/s, Loss=5.5595, Avg Loss=5.5588]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 2, Loss: 5.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  19%|█▉        | 5/26 [00:01<00:06,  3.22it/s, Loss=5.5578, Avg Loss=5.5581]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 4, Loss: 5.5578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  27%|██▋       | 7/26 [00:02<00:05,  3.28it/s, Loss=5.5560, Avg Loss=5.5579]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 6, Loss: 5.5560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  35%|███▍      | 9/26 [00:03<00:05,  3.28it/s, Loss=5.5496, Avg Loss=5.5562]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 8, Loss: 5.5496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  42%|████▏     | 11/26 [00:03<00:04,  3.05it/s, Loss=5.5463, Avg Loss=5.5555]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 10, Loss: 5.5463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  50%|█████     | 13/26 [00:04<00:03,  3.51it/s, Loss=5.5498, Avg Loss=5.5551]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 12, Loss: 5.5498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  58%|█████▊    | 15/26 [00:04<00:03,  3.45it/s, Loss=5.5566, Avg Loss=5.5554]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 14, Loss: 5.5566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  65%|██████▌   | 17/26 [00:05<00:02,  3.65it/s, Loss=5.5530, Avg Loss=5.5557]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 16, Loss: 5.5530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  73%|███████▎  | 19/26 [00:05<00:02,  3.41it/s, Loss=5.5535, Avg Loss=5.5557]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 18, Loss: 5.5535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  81%|████████  | 21/26 [00:06<00:01,  3.32it/s, Loss=5.5573, Avg Loss=5.5557]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 20, Loss: 5.5573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  88%|████████▊ | 23/26 [00:07<00:00,  3.33it/s, Loss=5.5615, Avg Loss=5.5558]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 22, Loss: 5.5615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  96%|█████████▌| 25/26 [00:07<00:00,  3.24it/s, Loss=5.5589, Avg Loss=5.5559]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 24, Loss: 5.5589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 26/26 [00:08<00:00,  3.20it/s, Loss=5.5535, Avg Loss=5.5558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Train Loss: 5.555764, LR: 1.00e-06, Time: 8.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:   4%|▍         | 1/26 [00:00<00:15,  1.63it/s, Loss=5.5557, Avg Loss=5.5557]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 0, Loss: 5.5557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  12%|█▏        | 3/26 [00:01<00:09,  2.40it/s, Loss=5.5521, Avg Loss=5.5533]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 2, Loss: 5.5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  19%|█▉        | 5/26 [00:01<00:06,  3.14it/s, Loss=5.5477, Avg Loss=5.5529]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 4, Loss: 5.5477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  27%|██▋       | 7/26 [00:02<00:05,  3.23it/s, Loss=5.5544, Avg Loss=5.5545]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 6, Loss: 5.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  35%|███▍      | 9/26 [00:03<00:05,  3.22it/s, Loss=5.5586, Avg Loss=5.5551]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 8, Loss: 5.5586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  42%|████▏     | 11/26 [00:03<00:04,  3.01it/s, Loss=5.5539, Avg Loss=5.5549]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 10, Loss: 5.5539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  50%|█████     | 13/26 [00:04<00:03,  3.50it/s, Loss=5.5535, Avg Loss=5.5548]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 12, Loss: 5.5535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  58%|█████▊    | 15/26 [00:04<00:03,  3.47it/s, Loss=5.5459, Avg Loss=5.5541]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 14, Loss: 5.5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  65%|██████▌   | 17/26 [00:05<00:02,  3.66it/s, Loss=5.5490, Avg Loss=5.5539]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 16, Loss: 5.5490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  73%|███████▎  | 19/26 [00:06<00:02,  3.38it/s, Loss=5.5497, Avg Loss=5.5537]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 18, Loss: 5.5497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  81%|████████  | 21/26 [00:06<00:01,  3.29it/s, Loss=5.5538, Avg Loss=5.5534]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 20, Loss: 5.5538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  88%|████████▊ | 23/26 [00:07<00:00,  3.34it/s, Loss=5.5650, Avg Loss=5.5538]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 22, Loss: 5.5650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  96%|█████████▌| 25/26 [00:07<00:00,  3.25it/s, Loss=5.5596, Avg Loss=5.5538]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 24, Loss: 5.5596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 26/26 [00:08<00:00,  3.17it/s, Loss=5.5540, Avg Loss=5.5538]\n",
      "Evaluating Epoch 10: 100%|██████████| 7/7 [00:01<00:00,  6.01it/s, Val Loss=5.0849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n",
      "Train Loss: 5.553835\n",
      "Val Loss: 5.483869\n",
      "Val mean similarity: -0.0431\n",
      "Learning Rate: 1.00e-06\n",
      "Epoch Time: 9.37s, Total Time: 163.79s\n",
      "------------------------------------------------------------\n",
      "Checkpoint saved: ../../../models/models_experiments/candidate_v1/checkpoints/checkpoint_epoch_10.pth\n",
      "New best model saved: ../../../models/models_experiments/candidate_v1/checkpoints/best_model.pth\n",
      "\n",
      "Training completed!\n",
      "Total training time: 0.05 hours\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "report_single_value() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal training time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_training_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m hours\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Log final metrics\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreport_single_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining Summary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTotal Training Time (hours)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_training_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m logger\u001b[38;5;241m.\u001b[39mreport_single_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Validation Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmin\u001b[39m(train_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_losses\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m train_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_losses\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    108\u001b[0m logger\u001b[38;5;241m.\u001b[39mreport_single_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Cosine Similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mmax\u001b[39m(train_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_similarities\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m train_history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_similarities\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: report_single_value() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# Training history for plotting\n",
    "train_history = {\n",
    "    'epochs': [],\n",
    "    'train_losses': [],\n",
    "    'val_losses': [],\n",
    "    'val_similarities': [],\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss, batch_losses = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, DEVICE, epoch\n",
    "    )\n",
    "    \n",
    "    # Log training loss every epoch\n",
    "    logger.report_scalar(\"Loss\", \"Train\", iteration=epoch, value=train_loss)\n",
    "    \n",
    "    \n",
    "    # Validation phase (every n epochs)\n",
    "    if epoch % eval_every_n_epochs == 0:\n",
    "        val_loss, val_similarity = evaluate_model(\n",
    "            model, val_loader, criterion, DEVICE, epoch\n",
    "        )\n",
    "        \n",
    "            \n",
    "        # Log results\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Log validation metrics to ClearML\n",
    "        logger.report_scalar(\"Loss\", \"Validation\", iteration=epoch, value=val_loss)\n",
    "        logger.report_scalar(\"Similarity\", \"Cosine Similarity\", iteration=epoch, value=val_similarity)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.6f}\")\n",
    "        print(f\"Val Loss: {val_loss:.6f}\")\n",
    "        print(f\"Val mean similarity: {val_similarity:.4f}\")\n",
    "        print(f\"Learning Rate: {current_lr:.2e}\")\n",
    "        print(f\"Epoch Time: {epoch_time:.2f}s, Total Time: {total_time:.2f}s\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Store history - convert numpy types to Python native types\n",
    "        train_history['epochs'].append(int(epoch))\n",
    "        train_history['train_losses'].append(float(train_loss))\n",
    "        train_history['val_losses'].append(float(val_loss))\n",
    "        train_history['val_similarities'].append(float(val_similarity))\n",
    "        \n",
    "        # Save checkpoint\n",
    "        save_checkpoint(\n",
    "            model, optimizer, epoch, \n",
    "            train_loss, val_loss, checkpoint_dir\n",
    "        )\n",
    "        \n",
    "        if epoch % (eval_every_n_epochs * 2) == 0 and len(train_history['epochs']) > 1:\n",
    "            # Create loss plot\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "            \n",
    "            # Loss plot\n",
    "            epochs_list = train_history['epochs']\n",
    "            ax1.plot(epochs_list, train_history['train_losses'], 'b-', label='Train Loss', linewidth=2)\n",
    "            ax1.plot(epochs_list, train_history['val_losses'], 'r-', label='Val Loss', linewidth=2)\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.set_title('Training and Validation Loss')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Similarity plot\n",
    "            ax2.plot(epochs_list, train_history['val_similarities'], 'g-', linewidth=2)\n",
    "            ax2.set_xlabel('Epoch')\n",
    "            ax2.set_ylabel('Cosine Similarity')\n",
    "            ax2.set_title('Validation Cosine Similarity')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Log plot to ClearML\n",
    "            logger.report_matplotlib_figure(\"Training Progress\", \"Loss and Similarity\", iteration=epoch, figure=plt)\n",
    "            plt.close()\n",
    "    \n",
    "    else:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.6f}, LR: {current_lr:.2e}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "# Final summary logging\n",
    "print(\"\\nTraining completed!\")\n",
    "total_training_time = (time.time() - start_time)/3600\n",
    "print(f\"Total training time: {total_training_time:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b84058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log final metrics\n",
    "logger.report_single_value(\"Total Training Time (hours)\", total_training_time)\n",
    "logger.report_single_value(\"Best Validation Loss\", min(train_history['val_losses']) if train_history['val_losses'] else float('inf'))\n",
    "logger.report_single_value(\"Best Cosine Similarity\", max(train_history['val_similarities']) if train_history['val_similarities'] else 0.0)\n",
    "logger.report_single_value(\"Total Epochs\", epochs)\n",
    "\n",
    "# Close the task\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSU-MS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3756c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dca8b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import required libraries\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load env variables\n",
    "load_dotenv('../../../.env')\n",
    "\n",
    "# Import your model and data loading components\n",
    "from dataloader.dataset_wrapper import create_wrapper_from_dataframe\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c2e974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=2dba1462897e474e98fad19f45e54c4d\n",
      "ClearML results page: https://app.clear.ml/projects/0fec81950d384f0294d2c713df3887db/experiments/2dba1462897e474e98fad19f45e54c4d/output/log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n",
      "ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n"
     ]
    }
   ],
   "source": [
    "# First install ClearML if not already installed: pip install clearml\n",
    "import clearml\n",
    "from clearml import Task, Logger\n",
    "\n",
    "# Initialize ClearML Task\n",
    "task = Task.init(project_name='CSMP_thesis_project', task_name='CSMP_traning_experiment_5', reuse_last_task_id=False)\n",
    "logger = Logger.current_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e857a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration and paths setup\n",
    "CONFIG_PATH = \"../../../configs/config.yaml\"\n",
    "TRAIN_CSV_PATH = \"../../../data/traning_and_validation/train_deduplicated.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44018e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices:\n",
      "  Device 0: NVIDIA A100 80GB PCIe\n",
      "    Total memory: 79.25 GB\n",
      "    Allocated memory: 0.00 GB\n",
      "    Free memory: 79.25 GB\n",
      "  Device 1: NVIDIA A100 80GB PCIe\n",
      "    Total memory: 79.25 GB\n",
      "    Allocated memory: 0.00 GB\n",
      "    Free memory: 79.25 GB\n",
      "\n",
      "Selected device 0 with 79.25 GB free memory\n",
      "Using CUDA for GPU acceleration\n",
      "Using device: cuda:0\n",
      "Validation data path: ../../../data/traning_and_validation/train_deduplicated.csv\n"
     ]
    }
   ],
   "source": [
    "# Device selection with automatic CUDA device selection based on free memory\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "    print(\"Using MPS (Metal Performance Shaders) for GPU acceleration\")\n",
    "elif torch.cuda.is_available():\n",
    "    # Find CUDA device with most free memory\n",
    "    max_free_memory = 0\n",
    "    best_device = 0\n",
    "    \n",
    "    print(\"Available CUDA devices:\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        torch.cuda.set_device(i)\n",
    "        torch.cuda.empty_cache()  # Clear cache to get accurate memory info\n",
    "        \n",
    "        total_memory = torch.cuda.get_device_properties(i).total_memory\n",
    "        allocated_memory = torch.cuda.memory_allocated(i)\n",
    "        free_memory = total_memory - allocated_memory\n",
    "        \n",
    "        print(f\"  Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"    Total memory: {total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"    Allocated memory: {allocated_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"    Free memory: {free_memory / 1024**3:.2f} GB\")\n",
    "        \n",
    "        if free_memory > max_free_memory:\n",
    "            max_free_memory = free_memory\n",
    "            best_device = i\n",
    "    \n",
    "    DEVICE = f'cuda:{best_device}'\n",
    "    print(f\"\\nSelected device {best_device} with {max_free_memory / 1024**3:.2f} GB free memory\")\n",
    "    print(\"Using CUDA for GPU acceleration\")\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Validation data path: {TRAIN_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1203af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = f'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9502b6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configuration...\n",
      "Configuration loaded:\n",
      "- Batch size: 256\n",
      "- Model config keys: []\n",
      "- Loss config: {'temperature': 0.3, 'use_cosine_similarity': True, 'alpha_weight': 0.75}\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load configuration\n",
    "print(\"Loading configuration...\")\n",
    "config = yaml.load(open(CONFIG_PATH, \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Batch size: {config.get('batch_size', 64)}\")\n",
    "print(f\"- Model config keys: {list(config.get('model', {}).keys())}\")\n",
    "print(f\"- Loss config: {config.get('loss', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e06fc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 256,\n",
       " 'epochs': 100,\n",
       " 'eval_every_n_epochs': 5,\n",
       " 'log_every_n_steps': 10,\n",
       " 'learning_rate': '1e-05',\n",
       " 'weight_decay': '1e-6',\n",
       " 'valid_size': 0.2,\n",
       " 'fp16_precision': True,\n",
       " 'truncation': True,\n",
       " 'sample_size': 10000,\n",
       " 'model_config': {'emb_dim': 256,\n",
       "  'spec_embed_dim': 256,\n",
       "  'embed_dim': 128,\n",
       "  'feat_dim': 512,\n",
       "  'num_layer': 5,\n",
       "  'layers': 5,\n",
       "  'drop_ratio': 0.3,\n",
       "  'dropout': 0.1,\n",
       "  'pool': 'mean'},\n",
       " 'loss': {'temperature': 0.3,\n",
       "  'use_cosine_similarity': True,\n",
       "  'alpha_weight': 0.75}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.connect(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbfbadd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data...\n",
      "Validation dataset shape: (798444, 10)\n",
      "Columns: ['peaks_json', 'ion_source', 'compound_source', 'instrument', 'adduct', 'precursor_mz', 'smiles', 'inchikey', 'ion_mode', 'molecular_formula']\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peaks_json</th>\n",
       "      <th>ion_source</th>\n",
       "      <th>compound_source</th>\n",
       "      <th>instrument</th>\n",
       "      <th>adduct</th>\n",
       "      <th>precursor_mz</th>\n",
       "      <th>smiles</th>\n",
       "      <th>inchikey</th>\n",
       "      <th>ion_mode</th>\n",
       "      <th>molecular_formula</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[42.014248, 0.10199999999999998], [42.26601, ...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[49.01717, 0.155], [49.020023, 0.253], [67.05...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[49.017338, 0.242], [49.020237, 0.181], [67.0...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[49.01701, 0.144], [49.019947, 0.244], [139.0...</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[49.017166, 0.155], [49.020008, 0.253], [139....</td>\n",
       "      <td>ESI</td>\n",
       "      <td>Crude</td>\n",
       "      <td>Orbitrap</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>377.186</td>\n",
       "      <td>CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...</td>\n",
       "      <td>RNKMIWQDRWSWCD-UHFFFAOYSA-N</td>\n",
       "      <td>Positive</td>\n",
       "      <td>C23H24N2O3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          peaks_json ion_source  \\\n",
       "0  [[42.014248, 0.10199999999999998], [42.26601, ...        ESI   \n",
       "1  [[49.01717, 0.155], [49.020023, 0.253], [67.05...        ESI   \n",
       "2  [[49.017338, 0.242], [49.020237, 0.181], [67.0...        ESI   \n",
       "3  [[49.01701, 0.144], [49.019947, 0.244], [139.0...        ESI   \n",
       "4  [[49.017166, 0.155], [49.020008, 0.253], [139....        ESI   \n",
       "\n",
       "  compound_source instrument  adduct  precursor_mz  \\\n",
       "0           Crude   Orbitrap  [M+H]+       377.186   \n",
       "1           Crude   Orbitrap  [M+H]+       377.186   \n",
       "2           Crude   Orbitrap  [M+H]+       377.186   \n",
       "3           Crude   Orbitrap  [M+H]+       377.186   \n",
       "4           Crude   Orbitrap  [M+H]+       377.186   \n",
       "\n",
       "                                              smiles  \\\n",
       "0  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "1  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "2  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "3  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "4  CC12CCC(C(=O)N(CNc3cc4c(cc3)c3ccccc3o4)C1=O)C2...   \n",
       "\n",
       "                      inchikey  ion_mode molecular_formula  \n",
       "0  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "1  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "2  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "3  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  \n",
       "4  RNKMIWQDRWSWCD-UHFFFAOYSA-N  Positive        C23H24N2O3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Load and explore validation data\n",
    "print(\"Loading train data...\")\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "\n",
    "print(f\"Validation dataset shape: {df_train.shape}\")\n",
    "print(f\"Columns: {list(df_train.columns)}\")\n",
    "print(f\"Sample data:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da40ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample = df_train.sample(n=config.get('sample_size'),random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed921164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data loaders\n",
      "Converting DataFrame to compatible files...\n",
      "Processed 10000 valid spectra out of 10000 total entries.\n",
      "Create data wrapper\n",
      "Total spectra: 10000\n",
      "Unique molecules: 7805\n",
      "Training spectra: 7983 from 6244 molecules\n",
      "Validation spectra: 2017 from 1561 molecules\n",
      "✓ No molecule overlap between train and validation sets\n",
      "calculating molecular graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 567/7983 [00:01<00:29, 253.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C2=CC=C(O)C(=C2OC(=C1C=3C=CC=4OCCCOC4C3)C)C[NH+](C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1141/7983 [00:02<00:11, 601.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES CCC1=C(C2=NC1=CC3=C(C4=C([N-]3)C(=C5[C@H]([C@@H](C(=N5)C=C6C(=C(C(=C2)[N-]6)C=C)C)C)CCC(=O)OC/C=C(\\C)/CCC[C@H](C)CCC[C@H](C)CCCC(C)C)[C@H](C4=O)C(=O)OC)C)C=O.[Mg+2] calculation failure\n",
      "SMILES [Na+].O=P([O-])(O)OCC1OC(N2C=NC=3C(=NC=NC32)N)C(O)C1O calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1662/7983 [00:03<00:09, 638.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [K+].O=S(=O)([O-])ON=C(SC1OC(CO)C(O)C(O)C1O)CC=C.O calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2236/7983 [00:04<00:09, 627.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C(=COC2=C1C=C(C(O)=C2C[NH+](C)C)CC)C=3C=CC=4OCCOC4C3 calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3446/7983 [00:06<00:07, 605.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES C1C(N(C2=C(N1)N=C(NC2=O)N)C=O)CNC3=CC=C(C=C3)C(=O)N[C@@H](CCC(=O)[O-])C(=O)[O-].[Ca+2] calculation failure\n",
      "SMILES [Cl-].O=C1C2=CC=C(O)C(=C2OC(=C1C=3C=CC=4OCCCOC4C3)C)C[NH+](C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 3764/7983 [00:06<00:06, 625.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].OC=1C=C(O)C=2C=C(OC3OC(CO)C(O)C(O)C3O)C(=[O+]C2C1)C=4C=CC(O)=C(O)C4 calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 4081/7983 [00:07<00:06, 621.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [K+].[K+].O=C([O-])C1OC(OC2C(OC(C(=O)[O-])C(O)C2O)OC3CCC4(C)C5C(=O)C=C6C7CC(C(=O)O)(C)CCC7(C)CCC6(C)C5(C)CCC4C3(C)C)C(O)C(O)C1O calculation failure\n",
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 5042/7983 [00:09<00:04, 615.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=C([O-])C(CC)C1OC(C(=CC=CC2C=CC3CCCC3C2C(=O)C4=CC=CN4)CC)C(C)CC1 calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 5233/7983 [00:09<00:04, 624.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [K+].O=S(=O)([O-])ON=C(SC1OC(CO)C(O)C(O)C1O)CC=C.O calculation failure\n",
      "SMILES [Cl-].O=C1C2=CC=C(O)C(=C2OC(=C1C=3C=CC=4OCCCOC4C3)C)C[NH+](C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 5424/7983 [00:09<00:04, 621.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 5682/7983 [00:10<00:03, 619.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C(O)C=1C=CC=CC1C=2C=3C=CC(=CC3OC4=CC(C=CC42)=[N+](CC)CC)N(CC)CC calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 5877/7983 [00:10<00:03, 629.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=C(CCCCCCCCCCC)CC(O)S(=O)(=O)[O-] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 6194/7983 [00:10<00:02, 621.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Na+].O=C(CCCCCCCCCCC)CC(O)S(=O)(=O)[O-] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 6447/7983 [00:11<00:02, 622.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n",
      "SMILES [Na+].O=C(CCCCCCCCCCC)CC(O)S(=O)(=O)[O-] calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 6887/7983 [00:12<00:01, 607.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [I-].O=C(OCC1=CC[N+]2(C)CCC(O)C12)C(O)(C(O)C)C(C)C calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 7198/7983 [00:12<00:01, 613.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].OC=1C=C(O)C=2C=C(OC3OC(CO)C(O)C(O)C3O)C(=[O+]C2C1)C=4C=CC(O)=C(O)C4 calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7983/7983 [00:13<00:00, 578.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 6850 molecular graph-mass spectrometry pairs\n",
      "calculating molecular graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 516/2017 [00:00<00:02, 642.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Cl-].O=C1C=2C=C(C(O)=C(C2OC(=C1C=3C=CC=4OCCOC4C3)C)C[NH+](C)C)CCC calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 908/2017 [00:01<00:01, 638.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [Br-].O=C(OC1CC2C3OC3C(C1)[N+]2(C)CCCC)C(C=4C=CC=CC4)CO calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1562/2017 [00:02<00:00, 635.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES [K+].O=C([O-])C12CCC(C(=C)C)C2C3CCC4C5(C)CCC(=O)C(C)(C)C5CCC4(C)C3(C)CC1 calculation failure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2017/2017 [00:03<00:00, 633.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated 1722 molecular graph-mass spectrometry pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Prepare validation data loader\n",
    "print(\"Preparing data loaders\")\n",
    "\n",
    "# Create data wrapper from DataFrame\n",
    "wrapper = create_wrapper_from_dataframe(\n",
    "    df=df_train_sample,\n",
    "    batch_size=config.get('batch_size'),  \n",
    "    num_workers=8,\n",
    "    valid_size=config.get('valid_size'),  \n",
    "    use_ddp=False,\n",
    "    output_dir=\"../../../data/train_feature/\",\n",
    "    recompute=True\n",
    ")\n",
    "\n",
    "# Get the data loader\n",
    "train_loader, val_loader = wrapper.get_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d777a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ModelCLR\n",
    "\n",
    "# Initialize model architecture\n",
    "model = ModelCLR(**config[\"model_config\"]).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc0c56bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelCLR(\n",
       "  (Smiles_model): SmilesModel(\n",
       "    (x_embedding1): Embedding(119, 256)\n",
       "    (x_embedding2): Embedding(4, 256)\n",
       "    (x_embedding3): Embedding(8, 256)\n",
       "    (x_embedding4): Embedding(6, 256)\n",
       "    (x_embedding5): Embedding(5, 256)\n",
       "    (gnns): ModuleList(\n",
       "      (0-4): 5 x GINEConv()\n",
       "    )\n",
       "    (batch_norms): ModuleList(\n",
       "      (0-4): 5 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (feat_lin): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (out_lin): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (MS_model): MSModel(\n",
       "    (mz_embedder): FourierEmbedder()\n",
       "    (input_compress): Linear(in_features=257, out_features=256, bias=True)\n",
       "    (peak_attn_layers): ModuleList(\n",
       "      (0-4): 5 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (pooling_layer): AdaptiveAvgPool1d(output_size=1)\n",
       "    (output_layer): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (smi_esa): ESA_SMILES(\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (spec_esa): ESA_SPEC(\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (smi_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (spec_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eab11f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMETER ANALYSIS:\n",
      "----------------------------------------\n",
      "Trainable Parameters: 6,102,784\n"
     ]
    }
   ],
   "source": [
    "# Parameter Count\n",
    "print(\"PARAMETER ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3e1bd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY ANALYSIS:\n",
      "----------------------------------------\n",
      "Model Size: 23.29 MB\n",
      "Parameter Memory: 23.28 MB\n",
      "Buffer Memory: 0.01 MB\n"
     ]
    }
   ],
   "source": [
    "# Memory Usage (approximate)\n",
    "print(\"MEMORY ANALYSIS:\")\n",
    "print(\"-\" * 40)\n",
    "param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "model_size_mb = (param_size + buffer_size) / 1024 / 1024\n",
    "\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"Parameter Memory: {param_size / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Buffer Memory: {buffer_size / 1024 / 1024:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f9e6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss.nt_xent import NTXentLoss\n",
    "\n",
    "# Initialize loss function\n",
    "temperature = config.get('loss', {}).get('temperature', 0.1)\n",
    "batch_size = config.get('batch_size', 512)\n",
    "use_cosine_similarity = config.get('loss', {}).get('use_cosine_similarity', True)\n",
    "alpha_weight = config.get('loss', {}).get('alpha_weight', 1.0)\n",
    "\n",
    "criterion = NTXentLoss(\n",
    "    device=DEVICE, \n",
    "    batch_size=batch_size, \n",
    "    temperature=temperature, \n",
    "    use_cosine_similarity=use_cosine_similarity, \n",
    "    alpha_weight=alpha_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca14bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up training components...\n",
      "Training for 100 epochs\n",
      "Optimizer: AdamW with lr=1e-05\n",
      "Checkpoint directory: ../../../models/models_experiments/candidate_v1/checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Training Setup and Optimizer\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "print(\"Setting up training components...\")\n",
    "OUTPUT_DIR = \"../../../models/models_experiments/candidate_v1\"\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=float(config.get('learning_rate', 1e-05)),\n",
    "    weight_decay=float(config.get('weight_decay', 1e-05))\n",
    ")\n",
    "\n",
    "# Training configuration\n",
    "epochs = config.get('epochs', 100)\n",
    "eval_every_n_epochs = config.get('eval_every_n_epochs', 5)\n",
    "log_every_n_steps = config.get('log_every_n_steps', 2)\n",
    "\n",
    "# Add ReduceLROnPlateau scheduler for representation learning\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',           # minimize validation loss\n",
    "    factor=0.5,           # reduce LR by half\n",
    "    patience=3,             \n",
    "    verbose=True,\n",
    "    min_lr=1e-6,\n",
    "    threshold=1e-4\n",
    ")\n",
    "\n",
    "# Create checkpoint directory\n",
    "checkpoint_dir = os.path.join(OUTPUT_DIR, \"checkpoints\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Training for {epochs} epochs\")\n",
    "print(f\"Optimizer: AdamW with lr={config.get('learning_rate', 5e-6)}\")\n",
    "print(f\"Checkpoint directory: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2270602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Training and Evaluation Functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    batch_losses = []\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch}\")\n",
    "    \n",
    "    for batch_idx, (graphs, mzs, intensities, num_peaks) in enumerate(progress_bar):\n",
    "        \n",
    "        # Move data to device\n",
    "        graphs = graphs.to(device)\n",
    "        mzs = mzs.to(device)\n",
    "        intensities = intensities.to(device)\n",
    "        num_peaks = num_peaks.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        mol_features, spec_features = model(graphs, mzs, intensities, num_peaks)\n",
    "        loss = criterion(mol_features, spec_features)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track loss\n",
    "        batch_loss = loss.item()\n",
    "        total_loss += batch_loss\n",
    "        batch_losses.append(batch_loss)\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{batch_loss:.4f}',\n",
    "            'Avg Loss': f'{total_loss/num_batches:.4f}'\n",
    "        })\n",
    "        \n",
    "        # Log every n steps\n",
    "        if batch_idx % log_every_n_steps == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {batch_loss:.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss, batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dadfa2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    molecular_features_list = []\n",
    "    spectral_features_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=f\"Evaluating Epoch {epoch}\")\n",
    "        \n",
    "        for batch_idx, (graphs, mzs, intensities, num_peaks) in enumerate(progress_bar):\n",
    "            # Move data to device\n",
    "            graphs = graphs.to(device)\n",
    "            mzs = mzs.to(device)\n",
    "            intensities = intensities.to(device)\n",
    "            num_peaks = num_peaks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            mol_features, spec_features = model(graphs, mzs, intensities, num_peaks)\n",
    "            loss = criterion(mol_features, spec_features)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Normalize features before storing \n",
    "            mol_features_norm = torch.nn.functional.normalize(mol_features, p=2, dim=1)\n",
    "            spec_features_norm = torch.nn.functional.normalize(spec_features, p=2, dim=1)\n",
    "            \n",
    "            # Store normalized features for retrieval metrics\n",
    "            molecular_features_list.append(mol_features_norm.cpu().numpy())\n",
    "            spectral_features_list.append(spec_features_norm.cpu().numpy())\n",
    "            \n",
    "            progress_bar.set_postfix({'Val Loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    \n",
    "    # Compute retrieval metrics\n",
    "    all_mol_features = np.vstack(molecular_features_list)\n",
    "    all_spec_features = np.vstack(spectral_features_list)\n",
    "        \n",
    "    # Compute cosine similarities\n",
    "    cosine_similarities = np.sum(all_mol_features * all_spec_features, axis=1)\n",
    "    mean_similarity = np.mean(cosine_similarities)\n",
    "        \n",
    "    return avg_loss, mean_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df13de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, train_loss, val_loss, checkpoint_dir):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'config': config\n",
    "    }\n",
    "    \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    # Save best model\n",
    "    best_checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "    if not os.path.exists(best_checkpoint_path):\n",
    "        torch.save(checkpoint, best_checkpoint_path)\n",
    "        print(f\"Best model saved: {best_checkpoint_path}\")\n",
    "    else:\n",
    "        best_checkpoint = torch.load(best_checkpoint_path)\n",
    "        if val_loss < best_checkpoint['val_loss']:\n",
    "            torch.save(checkpoint, best_checkpoint_path)\n",
    "            print(f\"New best model saved: {best_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7034d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   4%|▍         | 1/26 [00:01<00:25,  1.00s/it, Loss=5.5561, Avg Loss=5.5561]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 5.5561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  42%|████▏     | 11/26 [00:04<00:04,  3.36it/s, Loss=5.5449, Avg Loss=5.5500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Loss: 5.5449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:  81%|████████  | 21/26 [00:07<00:01,  3.22it/s, Loss=5.5469, Avg Loss=5.5489]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 20, Loss: 5.5469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 26/26 [00:08<00:00,  2.92it/s, Loss=5.5432, Avg Loss=5.5484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Train Loss: 5.548429, LR: 1.00e-05, Time: 8.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:   4%|▍         | 1/26 [00:01<00:26,  1.06s/it, Loss=5.5470, Avg Loss=5.5470]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 0, Loss: 5.5470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  42%|████▏     | 11/26 [00:04<00:04,  3.24it/s, Loss=5.5462, Avg Loss=5.5460]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 10, Loss: 5.5462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2:  81%|████████  | 21/26 [00:07<00:01,  3.20it/s, Loss=5.5487, Avg Loss=5.5458]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 20, Loss: 5.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 26/26 [00:08<00:00,  2.98it/s, Loss=5.5469, Avg Loss=5.5460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 - Train Loss: 5.546022, LR: 1.00e-05, Time: 8.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:   4%|▍         | 1/26 [00:00<00:22,  1.10it/s, Loss=5.5482, Avg Loss=5.5482]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 0, Loss: 5.5482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  42%|████▏     | 11/26 [00:03<00:04,  3.15it/s, Loss=5.5475, Avg Loss=5.5456]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 10, Loss: 5.5475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3:  81%|████████  | 21/26 [00:06<00:01,  3.28it/s, Loss=5.5472, Avg Loss=5.5456]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 20, Loss: 5.5472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 26/26 [00:08<00:00,  3.01it/s, Loss=5.5451, Avg Loss=5.5453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 - Train Loss: 5.545349, LR: 1.00e-05, Time: 8.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:   4%|▍         | 1/26 [00:00<00:22,  1.10it/s, Loss=5.5450, Avg Loss=5.5450]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 0, Loss: 5.5450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  42%|████▏     | 11/26 [00:03<00:04,  3.42it/s, Loss=5.5448, Avg Loss=5.5449]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 10, Loss: 5.5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4:  81%|████████  | 21/26 [00:07<00:01,  3.09it/s, Loss=5.5436, Avg Loss=5.5448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Batch 20, Loss: 5.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 26/26 [00:08<00:00,  3.00it/s, Loss=5.5466, Avg Loss=5.5448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 - Train Loss: 5.544811, LR: 1.00e-05, Time: 8.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:   4%|▍         | 1/26 [00:00<00:20,  1.20it/s, Loss=5.5470, Avg Loss=5.5470]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 0, Loss: 5.5470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  42%|████▏     | 11/26 [00:03<00:04,  3.19it/s, Loss=5.5450, Avg Loss=5.5453]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 10, Loss: 5.5450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:  81%|████████  | 21/26 [00:06<00:01,  3.16it/s, Loss=5.5445, Avg Loss=5.5447]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Batch 20, Loss: 5.5445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 26/26 [00:08<00:00,  3.00it/s, Loss=5.5460, Avg Loss=5.5449]\n",
      "Evaluating Epoch 5: 100%|██████████| 7/7 [00:01<00:00,  4.50it/s, Val Loss=5.2212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/100\n",
      "Train Loss: 5.544893\n",
      "Val Loss: 5.500609\n",
      "Val mean similarity: -0.0277\n",
      "Learning Rate: 1.00e-05\n",
      "Epoch Time: 10.22s, Total Time: 45.18s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:   4%|▍         | 1/26 [00:00<00:22,  1.13it/s, Loss=5.5394, Avg Loss=5.5394]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 0, Loss: 5.5394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  42%|████▏     | 11/26 [00:03<00:04,  3.05it/s, Loss=5.5489, Avg Loss=5.5452]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 10, Loss: 5.5489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6:  81%|████████  | 21/26 [00:07<00:01,  3.17it/s, Loss=5.5444, Avg Loss=5.5450]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Batch 20, Loss: 5.5444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 26/26 [00:08<00:00,  2.96it/s, Loss=5.5423, Avg Loss=5.5449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 - Train Loss: 5.544889, LR: 1.00e-05, Time: 8.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:   4%|▍         | 1/26 [00:00<00:22,  1.12it/s, Loss=5.5422, Avg Loss=5.5422]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 0, Loss: 5.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  42%|████▏     | 11/26 [00:04<00:04,  3.03it/s, Loss=5.5460, Avg Loss=5.5449]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 10, Loss: 5.5460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7:  81%|████████  | 21/26 [00:07<00:01,  3.10it/s, Loss=5.5490, Avg Loss=5.5453]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Batch 20, Loss: 5.5490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 26/26 [00:08<00:00,  2.92it/s, Loss=5.5466, Avg Loss=5.5452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 - Train Loss: 5.545202, LR: 1.00e-05, Time: 8.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:   4%|▍         | 1/26 [00:00<00:19,  1.26it/s, Loss=5.5456, Avg Loss=5.5456]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 0, Loss: 5.5456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  42%|████▏     | 11/26 [00:03<00:04,  3.32it/s, Loss=5.5432, Avg Loss=5.5443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 10, Loss: 5.5432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8:  81%|████████  | 21/26 [00:07<00:01,  3.20it/s, Loss=5.5445, Avg Loss=5.5448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Batch 20, Loss: 5.5445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 26/26 [00:08<00:00,  3.03it/s, Loss=5.5457, Avg Loss=5.5450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 - Train Loss: 5.545001, LR: 1.00e-05, Time: 8.60s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:   4%|▍         | 1/26 [00:00<00:20,  1.24it/s, Loss=5.5470, Avg Loss=5.5470]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 0, Loss: 5.5470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  42%|████▏     | 11/26 [00:03<00:04,  3.28it/s, Loss=5.5430, Avg Loss=5.5458]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 10, Loss: 5.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9:  81%|████████  | 21/26 [00:06<00:01,  3.45it/s, Loss=5.5405, Avg Loss=5.5448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Batch 20, Loss: 5.5405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 26/26 [00:08<00:00,  3.00it/s, Loss=5.5448, Avg Loss=5.5446]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 - Train Loss: 5.544621, LR: 1.00e-05, Time: 8.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:   4%|▍         | 1/26 [00:00<00:21,  1.16it/s, Loss=5.5416, Avg Loss=5.5416]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 0, Loss: 5.5416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  42%|████▏     | 11/26 [00:03<00:04,  3.20it/s, Loss=5.5458, Avg Loss=5.5444]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 10, Loss: 5.5458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10:  81%|████████  | 21/26 [00:07<00:01,  3.33it/s, Loss=5.5384, Avg Loss=5.5436]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Batch 20, Loss: 5.5384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 26/26 [00:08<00:00,  2.98it/s, Loss=5.5426, Avg Loss=5.5437]\n",
      "Evaluating Epoch 10: 100%|██████████| 7/7 [00:01<00:00,  5.17it/s, Val Loss=5.2213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/100\n",
      "Train Loss: 5.543704\n",
      "Val Loss: 5.501530\n",
      "Val mean similarity: -0.0163\n",
      "Learning Rate: 1.00e-05\n",
      "Epoch Time: 10.10s, Total Time: 90.24s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11:   4%|▍         | 1/26 [00:00<00:20,  1.22it/s, Loss=5.5410, Avg Loss=5.5410]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Batch 0, Loss: 5.5410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11:  42%|████▏     | 11/26 [00:03<00:04,  3.31it/s, Loss=5.5404, Avg Loss=5.5434]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Batch 10, Loss: 5.5404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11:  81%|████████  | 21/26 [00:07<00:01,  3.23it/s, Loss=5.5450, Avg Loss=5.5443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Batch 20, Loss: 5.5450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 26/26 [00:08<00:00,  2.97it/s, Loss=5.5460, Avg Loss=5.5448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 - Train Loss: 5.544779, LR: 1.00e-05, Time: 8.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12:   4%|▍         | 1/26 [00:00<00:18,  1.35it/s, Loss=5.5426, Avg Loss=5.5426]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Batch 0, Loss: 5.5426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12:  42%|████▏     | 11/26 [00:03<00:04,  3.68it/s, Loss=5.5455, Avg Loss=5.5457]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Batch 10, Loss: 5.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12:  81%|████████  | 21/26 [00:06<00:01,  3.24it/s, Loss=5.5438, Avg Loss=5.5441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Batch 20, Loss: 5.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 26/26 [00:08<00:00,  3.04it/s, Loss=5.5428, Avg Loss=5.5441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 - Train Loss: 5.544077, LR: 1.00e-05, Time: 8.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13:   4%|▍         | 1/26 [00:01<00:27,  1.10s/it, Loss=5.5496, Avg Loss=5.5496]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Batch 0, Loss: 5.5496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13:  42%|████▏     | 11/26 [00:04<00:04,  3.11it/s, Loss=5.5434, Avg Loss=5.5438]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Batch 10, Loss: 5.5434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13:  81%|████████  | 21/26 [00:08<00:01,  2.77it/s, Loss=5.5451, Avg Loss=5.5439]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Batch 20, Loss: 5.5451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 26/26 [00:09<00:00,  2.69it/s, Loss=5.5404, Avg Loss=5.5439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 - Train Loss: 5.543907, LR: 1.00e-05, Time: 9.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14:   4%|▍         | 1/26 [00:01<00:27,  1.09s/it, Loss=5.5402, Avg Loss=5.5402]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Batch 0, Loss: 5.5402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14:  42%|████▏     | 11/26 [00:05<00:06,  2.18it/s, Loss=5.5413, Avg Loss=5.5417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Batch 10, Loss: 5.5413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14:  81%|████████  | 21/26 [00:07<00:01,  3.50it/s, Loss=5.5418, Avg Loss=5.5427]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Batch 20, Loss: 5.5418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 26/26 [00:09<00:00,  2.70it/s, Loss=5.5457, Avg Loss=5.5429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 - Train Loss: 5.542893, LR: 1.00e-05, Time: 9.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15:   4%|▍         | 1/26 [00:00<00:24,  1.03it/s, Loss=5.5448, Avg Loss=5.5448]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Batch 0, Loss: 5.5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15:  42%|████▏     | 11/26 [00:04<00:04,  3.14it/s, Loss=5.5394, Avg Loss=5.5437]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Batch 10, Loss: 5.5394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15:  81%|████████  | 21/26 [00:07<00:01,  3.43it/s, Loss=5.5363, Avg Loss=5.5434]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Batch 20, Loss: 5.5363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 26/26 [00:08<00:00,  3.00it/s, Loss=5.5456, Avg Loss=5.5432]\n",
      "Evaluating Epoch 15: 100%|██████████| 7/7 [00:01<00:00,  4.88it/s, Val Loss=5.2214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/100\n",
      "Train Loss: 5.543209\n",
      "Val Loss: 5.501758\n",
      "Val mean similarity: -0.0106\n",
      "Learning Rate: 1.00e-05\n",
      "Epoch Time: 10.11s, Total Time: 137.87s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16:   4%|▍         | 1/26 [00:00<00:22,  1.11it/s, Loss=5.5460, Avg Loss=5.5460]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Batch 0, Loss: 5.5460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16:  42%|████▏     | 11/26 [00:03<00:04,  3.15it/s, Loss=5.5433, Avg Loss=5.5438]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Batch 10, Loss: 5.5433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16:  81%|████████  | 21/26 [00:07<00:01,  3.46it/s, Loss=5.5325, Avg Loss=5.5425]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Batch 20, Loss: 5.5325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 26/26 [00:08<00:00,  3.01it/s, Loss=5.5436, Avg Loss=5.5424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 - Train Loss: 5.542415, LR: 1.00e-05, Time: 8.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17:   4%|▍         | 1/26 [00:00<00:18,  1.37it/s, Loss=5.5438, Avg Loss=5.5438]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Batch 0, Loss: 5.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17:  42%|████▏     | 11/26 [00:03<00:04,  3.15it/s, Loss=5.5498, Avg Loss=5.5420]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Batch 10, Loss: 5.5498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17:  81%|████████  | 21/26 [00:06<00:01,  3.00it/s, Loss=5.5482, Avg Loss=5.5428]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Batch 20, Loss: 5.5482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 26/26 [00:08<00:00,  3.04it/s, Loss=5.5398, Avg Loss=5.5427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 - Train Loss: 5.542673, LR: 1.00e-05, Time: 8.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18:   4%|▍         | 1/26 [00:00<00:22,  1.11it/s, Loss=5.5472, Avg Loss=5.5472]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Batch 0, Loss: 5.5472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18:  42%|████▏     | 11/26 [00:04<00:05,  2.88it/s, Loss=5.5301, Avg Loss=5.5409]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Batch 10, Loss: 5.5301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18:  81%|████████  | 21/26 [00:07<00:01,  2.92it/s, Loss=5.5469, Avg Loss=5.5415]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Batch 20, Loss: 5.5469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 26/26 [00:09<00:00,  2.73it/s, Loss=5.5414, Avg Loss=5.5421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 - Train Loss: 5.542150, LR: 1.00e-05, Time: 9.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19:   4%|▍         | 1/26 [00:00<00:21,  1.14it/s, Loss=5.5346, Avg Loss=5.5346]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Batch 0, Loss: 5.5346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19:  42%|████▏     | 11/26 [00:03<00:04,  3.35it/s, Loss=5.5403, Avg Loss=5.5402]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Batch 10, Loss: 5.5403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19:  81%|████████  | 21/26 [00:07<00:01,  3.05it/s, Loss=5.5468, Avg Loss=5.5421]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Batch 20, Loss: 5.5468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 26/26 [00:08<00:00,  2.96it/s, Loss=5.5393, Avg Loss=5.5423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 - Train Loss: 5.542293, LR: 1.00e-05, Time: 8.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20:   4%|▍         | 1/26 [00:01<00:27,  1.08s/it, Loss=5.5479, Avg Loss=5.5479]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Batch 0, Loss: 5.5479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20:  42%|████▏     | 11/26 [00:04<00:04,  3.53it/s, Loss=5.5375, Avg Loss=5.5405]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Batch 10, Loss: 5.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20:  81%|████████  | 21/26 [00:07<00:01,  3.46it/s, Loss=5.5368, Avg Loss=5.5401]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Batch 20, Loss: 5.5368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 26/26 [00:08<00:00,  2.95it/s, Loss=5.5422, Avg Loss=5.5403]\n",
      "Evaluating Epoch 20: 100%|██████████| 7/7 [00:01<00:00,  4.77it/s, Val Loss=5.2296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/100\n",
      "Train Loss: 5.540296\n",
      "Val Loss: 5.505402\n",
      "Val mean similarity: 0.0031\n",
      "Learning Rate: 1.00e-05\n",
      "Epoch Time: 10.30s, Total Time: 183.72s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21:   4%|▍         | 1/26 [00:00<00:23,  1.08it/s, Loss=5.5304, Avg Loss=5.5304]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Batch 0, Loss: 5.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21:  42%|████▏     | 11/26 [00:04<00:04,  3.17it/s, Loss=5.5399, Avg Loss=5.5394]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Batch 10, Loss: 5.5399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21:  81%|████████  | 21/26 [00:06<00:01,  3.10it/s, Loss=5.5304, Avg Loss=5.5408]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Batch 20, Loss: 5.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 26/26 [00:08<00:00,  2.89it/s, Loss=5.5427, Avg Loss=5.5416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 - Train Loss: 5.541597, LR: 1.00e-05, Time: 8.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22:   4%|▍         | 1/26 [00:01<00:43,  1.72s/it, Loss=5.5344, Avg Loss=5.5344]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Batch 0, Loss: 5.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22:  42%|████▏     | 11/26 [00:04<00:04,  3.07it/s, Loss=5.5448, Avg Loss=5.5410]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Batch 10, Loss: 5.5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22:  81%|████████  | 21/26 [00:07<00:01,  3.43it/s, Loss=5.5436, Avg Loss=5.5415]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Batch 20, Loss: 5.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22: 100%|██████████| 26/26 [00:09<00:00,  2.76it/s, Loss=5.5396, Avg Loss=5.5416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 - Train Loss: 5.541568, LR: 1.00e-05, Time: 9.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23:   4%|▍         | 1/26 [00:01<00:26,  1.05s/it, Loss=5.5431, Avg Loss=5.5431]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Batch 0, Loss: 5.5431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23:  42%|████▏     | 11/26 [00:03<00:04,  3.20it/s, Loss=5.5388, Avg Loss=5.5387]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Batch 10, Loss: 5.5388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23:  81%|████████  | 21/26 [00:07<00:01,  2.98it/s, Loss=5.5373, Avg Loss=5.5399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Batch 20, Loss: 5.5373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 26/26 [00:08<00:00,  2.92it/s, Loss=5.5340, Avg Loss=5.5403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 - Train Loss: 5.540270, LR: 1.00e-05, Time: 8.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24:   4%|▍         | 1/26 [00:00<00:22,  1.13it/s, Loss=5.5415, Avg Loss=5.5415]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Batch 0, Loss: 5.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24:  42%|████▏     | 11/26 [00:03<00:04,  3.57it/s, Loss=5.5411, Avg Loss=5.5392]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Batch 10, Loss: 5.5411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24:  81%|████████  | 21/26 [00:06<00:01,  3.20it/s, Loss=5.5484, Avg Loss=5.5414]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Batch 20, Loss: 5.5484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 26/26 [00:08<00:00,  3.07it/s, Loss=5.5349, Avg Loss=5.5411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 - Train Loss: 5.541052, LR: 1.00e-05, Time: 8.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25:   4%|▍         | 1/26 [00:00<00:22,  1.11it/s, Loss=5.5499, Avg Loss=5.5499]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Batch 0, Loss: 5.5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25:  42%|████▏     | 11/26 [00:03<00:04,  3.17it/s, Loss=5.5451, Avg Loss=5.5414]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Batch 10, Loss: 5.5451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25:  81%|████████  | 21/26 [00:06<00:01,  2.79it/s, Loss=5.5462, Avg Loss=5.5389]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Batch 20, Loss: 5.5462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 26/26 [00:09<00:00,  2.70it/s, Loss=5.5377, Avg Loss=5.5395]\n",
      "Evaluating Epoch 25: 100%|██████████| 7/7 [00:01<00:00,  4.71it/s, Val Loss=5.2280]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/100\n",
      "Train Loss: 5.539466\n",
      "Val Loss: 5.505472\n",
      "Val mean similarity: 0.0109\n",
      "Learning Rate: 1.00e-05\n",
      "Epoch Time: 11.13s, Total Time: 231.53s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26:   4%|▍         | 1/26 [00:01<00:25,  1.00s/it, Loss=5.5380, Avg Loss=5.5380]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Batch 0, Loss: 5.5380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26:  42%|████▏     | 11/26 [00:03<00:04,  3.38it/s, Loss=5.5353, Avg Loss=5.5364]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Batch 10, Loss: 5.5353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26:  81%|████████  | 21/26 [00:07<00:01,  3.04it/s, Loss=5.5347, Avg Loss=5.5379]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Batch 20, Loss: 5.5347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 26/26 [00:08<00:00,  2.97it/s, Loss=5.5330, Avg Loss=5.5382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 - Train Loss: 5.538245, LR: 5.00e-06, Time: 8.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27:   4%|▍         | 1/26 [00:00<00:21,  1.18it/s, Loss=5.5384, Avg Loss=5.5384]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Batch 0, Loss: 5.5384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27:  42%|████▏     | 11/26 [00:03<00:04,  3.63it/s, Loss=5.5415, Avg Loss=5.5365]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Batch 10, Loss: 5.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27:  81%|████████  | 21/26 [00:06<00:01,  3.30it/s, Loss=5.5406, Avg Loss=5.5370]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Batch 20, Loss: 5.5406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 26/26 [00:08<00:00,  2.99it/s, Loss=5.5358, Avg Loss=5.5370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 - Train Loss: 5.537008, LR: 5.00e-06, Time: 8.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28:   4%|▍         | 1/26 [00:01<00:27,  1.12s/it, Loss=5.5446, Avg Loss=5.5446]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Batch 0, Loss: 5.5446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28:  42%|████▏     | 11/26 [00:04<00:04,  3.37it/s, Loss=5.5414, Avg Loss=5.5379]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Batch 10, Loss: 5.5414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28:  81%|████████  | 21/26 [00:07<00:01,  3.06it/s, Loss=5.5331, Avg Loss=5.5392]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Batch 20, Loss: 5.5331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28: 100%|██████████| 26/26 [00:08<00:00,  2.92it/s, Loss=5.5403, Avg Loss=5.5385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 - Train Loss: 5.538472, LR: 5.00e-06, Time: 8.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29:   4%|▍         | 1/26 [00:00<00:22,  1.13it/s, Loss=5.5400, Avg Loss=5.5400]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Batch 0, Loss: 5.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29:  42%|████▏     | 11/26 [00:03<00:04,  3.39it/s, Loss=5.5296, Avg Loss=5.5325]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Batch 10, Loss: 5.5296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29:  81%|████████  | 21/26 [00:07<00:02,  2.29it/s, Loss=5.5239, Avg Loss=5.5356]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Batch 20, Loss: 5.5239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 26/26 [00:09<00:00,  2.68it/s, Loss=5.5467, Avg Loss=5.5359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 - Train Loss: 5.535864, LR: 5.00e-06, Time: 9.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30:   4%|▍         | 1/26 [00:01<00:25,  1.02s/it, Loss=5.5441, Avg Loss=5.5441]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Batch 0, Loss: 5.5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30:  42%|████▏     | 11/26 [00:04<00:04,  3.30it/s, Loss=5.5376, Avg Loss=5.5361]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Batch 10, Loss: 5.5376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30:  81%|████████  | 21/26 [00:07<00:01,  2.97it/s, Loss=5.5334, Avg Loss=5.5366]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Batch 20, Loss: 5.5334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 26/26 [00:09<00:00,  2.88it/s, Loss=5.5357, Avg Loss=5.5365]\n",
      "Evaluating Epoch 30: 100%|██████████| 7/7 [00:01<00:00,  4.69it/s, Val Loss=5.2354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/100\n",
      "Train Loss: 5.536543\n",
      "Val Loss: 5.507898\n",
      "Val mean similarity: 0.0071\n",
      "Learning Rate: 5.00e-06\n",
      "Epoch Time: 10.52s, Total Time: 278.13s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31:   4%|▍         | 1/26 [00:00<00:22,  1.13it/s, Loss=5.5225, Avg Loss=5.5225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Batch 0, Loss: 5.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31:  42%|████▏     | 11/26 [00:04<00:04,  3.23it/s, Loss=5.5418, Avg Loss=5.5378]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Batch 10, Loss: 5.5418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31:  81%|████████  | 21/26 [00:07<00:01,  3.00it/s, Loss=5.5388, Avg Loss=5.5368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Batch 20, Loss: 5.5388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 26/26 [00:08<00:00,  2.92it/s, Loss=5.5416, Avg Loss=5.5370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 - Train Loss: 5.537034, LR: 5.00e-06, Time: 8.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32:   4%|▍         | 1/26 [00:00<00:24,  1.03it/s, Loss=5.5268, Avg Loss=5.5268]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Batch 0, Loss: 5.5268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32:  42%|████▏     | 11/26 [00:03<00:04,  3.52it/s, Loss=5.5432, Avg Loss=5.5377]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Batch 10, Loss: 5.5432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32:  81%|████████  | 21/26 [00:07<00:01,  3.27it/s, Loss=5.5422, Avg Loss=5.5365]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Batch 20, Loss: 5.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 26/26 [00:08<00:00,  2.96it/s, Loss=5.5410, Avg Loss=5.5359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 - Train Loss: 5.535860, LR: 5.00e-06, Time: 8.80s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33:   4%|▍         | 1/26 [00:01<00:25,  1.00s/it, Loss=5.5393, Avg Loss=5.5393]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Batch 0, Loss: 5.5393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33:  42%|████▏     | 11/26 [00:04<00:05,  2.85it/s, Loss=5.5393, Avg Loss=5.5389]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Batch 10, Loss: 5.5393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33:  81%|████████  | 21/26 [00:07<00:01,  3.14it/s, Loss=5.5406, Avg Loss=5.5381]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Batch 20, Loss: 5.5406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 26/26 [00:09<00:00,  2.69it/s, Loss=5.5300, Avg Loss=5.5377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 - Train Loss: 5.537709, LR: 5.00e-06, Time: 9.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34:   4%|▍         | 1/26 [00:00<00:22,  1.10it/s, Loss=5.5359, Avg Loss=5.5359]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Batch 0, Loss: 5.5359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34:  42%|████▏     | 11/26 [00:04<00:05,  2.89it/s, Loss=5.5283, Avg Loss=5.5334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Batch 10, Loss: 5.5283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34:  81%|████████  | 21/26 [00:07<00:01,  3.41it/s, Loss=5.5557, Avg Loss=5.5366]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Batch 20, Loss: 5.5557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 26/26 [00:08<00:00,  2.95it/s, Loss=5.5400, Avg Loss=5.5373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 - Train Loss: 5.537255, LR: 5.00e-06, Time: 8.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35:   4%|▍         | 1/26 [00:00<00:19,  1.28it/s, Loss=5.5295, Avg Loss=5.5295]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Batch 0, Loss: 5.5295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35:  42%|████▏     | 11/26 [00:03<00:04,  3.43it/s, Loss=5.5328, Avg Loss=5.5333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Batch 10, Loss: 5.5328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35:  81%|████████  | 21/26 [00:06<00:01,  3.47it/s, Loss=5.5402, Avg Loss=5.5358]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Batch 20, Loss: 5.5402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 26/26 [00:08<00:00,  3.01it/s, Loss=5.5238, Avg Loss=5.5358]\n",
      "Evaluating Epoch 35: 100%|██████████| 7/7 [00:01<00:00,  4.94it/s, Val Loss=5.2281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/100\n",
      "Train Loss: 5.535844\n",
      "Val Loss: 5.506888\n",
      "Val mean similarity: -0.0019\n",
      "Learning Rate: 5.00e-06\n",
      "Epoch Time: 10.07s, Total Time: 325.23s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36:   4%|▍         | 1/26 [00:00<00:19,  1.31it/s, Loss=5.5228, Avg Loss=5.5228]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Batch 0, Loss: 5.5228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36:  42%|████▏     | 11/26 [00:03<00:05,  2.94it/s, Loss=5.5417, Avg Loss=5.5350]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Batch 10, Loss: 5.5417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36:  81%|████████  | 21/26 [00:06<00:01,  3.29it/s, Loss=5.5210, Avg Loss=5.5352]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Batch 20, Loss: 5.5210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 26/26 [00:09<00:00,  2.88it/s, Loss=5.5409, Avg Loss=5.5353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 - Train Loss: 5.535338, LR: 5.00e-06, Time: 9.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37:   4%|▍         | 1/26 [00:01<00:47,  1.88s/it, Loss=5.5331, Avg Loss=5.5331]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Batch 0, Loss: 5.5331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37:  42%|████▏     | 11/26 [00:04<00:05,  2.91it/s, Loss=5.5512, Avg Loss=5.5339]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Batch 10, Loss: 5.5512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37:  81%|████████  | 21/26 [00:07<00:01,  3.22it/s, Loss=5.5247, Avg Loss=5.5363]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Batch 20, Loss: 5.5247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37: 100%|██████████| 26/26 [00:09<00:00,  2.70it/s, Loss=5.5234, Avg Loss=5.5359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 - Train Loss: 5.535950, LR: 5.00e-06, Time: 9.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38:   4%|▍         | 1/26 [00:00<00:23,  1.08it/s, Loss=5.5311, Avg Loss=5.5311]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Batch 0, Loss: 5.5311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38:  42%|████▏     | 11/26 [00:03<00:04,  3.07it/s, Loss=5.5375, Avg Loss=5.5371]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Batch 10, Loss: 5.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38:  81%|████████  | 21/26 [00:06<00:01,  3.01it/s, Loss=5.5276, Avg Loss=5.5372]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Batch 20, Loss: 5.5276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38: 100%|██████████| 26/26 [00:08<00:00,  3.01it/s, Loss=5.5179, Avg Loss=5.5368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 - Train Loss: 5.536771, LR: 5.00e-06, Time: 8.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39:   4%|▍         | 1/26 [00:00<00:20,  1.24it/s, Loss=5.5262, Avg Loss=5.5262]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Batch 0, Loss: 5.5262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39:  42%|████▏     | 11/26 [00:03<00:04,  3.36it/s, Loss=5.5419, Avg Loss=5.5331]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Batch 10, Loss: 5.5419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39:  81%|████████  | 21/26 [00:06<00:01,  3.59it/s, Loss=5.5478, Avg Loss=5.5342]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Batch 20, Loss: 5.5478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 26/26 [00:08<00:00,  3.05it/s, Loss=5.5384, Avg Loss=5.5341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 - Train Loss: 5.534134, LR: 5.00e-06, Time: 8.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40:   4%|▍         | 1/26 [00:00<00:21,  1.19it/s, Loss=5.5173, Avg Loss=5.5173]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Batch 0, Loss: 5.5173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40:  42%|████▏     | 11/26 [00:03<00:04,  3.34it/s, Loss=5.5362, Avg Loss=5.5332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Batch 10, Loss: 5.5362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40:  81%|████████  | 21/26 [00:07<00:01,  2.55it/s, Loss=5.5304, Avg Loss=5.5339]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Batch 20, Loss: 5.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40: 100%|██████████| 26/26 [00:09<00:00,  2.66it/s, Loss=5.5367, Avg Loss=5.5339]\n",
      "Evaluating Epoch 40: 100%|██████████| 7/7 [00:01<00:00,  4.73it/s, Val Loss=5.2279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/100\n",
      "Train Loss: 5.533920\n",
      "Val Loss: 5.509496\n",
      "Val mean similarity: 0.0002\n",
      "Learning Rate: 5.00e-06\n",
      "Epoch Time: 11.26s, Total Time: 372.40s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41:   4%|▍         | 1/26 [00:00<00:20,  1.21it/s, Loss=5.5445, Avg Loss=5.5445]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Batch 0, Loss: 5.5445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41:  42%|████▏     | 11/26 [00:04<00:04,  3.42it/s, Loss=5.5199, Avg Loss=5.5293]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Batch 10, Loss: 5.5199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41:  81%|████████  | 21/26 [00:07<00:01,  3.50it/s, Loss=5.5357, Avg Loss=5.5335]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Batch 20, Loss: 5.5357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41: 100%|██████████| 26/26 [00:08<00:00,  3.02it/s, Loss=5.5467, Avg Loss=5.5348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 - Train Loss: 5.534832, LR: 5.00e-06, Time: 8.62s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42:   4%|▍         | 1/26 [00:01<00:27,  1.08s/it, Loss=5.5325, Avg Loss=5.5325]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Batch 0, Loss: 5.5325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42:  42%|████▏     | 11/26 [00:04<00:04,  3.53it/s, Loss=5.5371, Avg Loss=5.5348]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Batch 10, Loss: 5.5371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42:  81%|████████  | 21/26 [00:07<00:01,  3.64it/s, Loss=5.5218, Avg Loss=5.5349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Batch 20, Loss: 5.5218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42: 100%|██████████| 26/26 [00:08<00:00,  2.96it/s, Loss=5.5420, Avg Loss=5.5346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 - Train Loss: 5.534605, LR: 5.00e-06, Time: 8.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43:   4%|▍         | 1/26 [00:00<00:20,  1.20it/s, Loss=5.5368, Avg Loss=5.5368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Batch 0, Loss: 5.5368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43:  42%|████▏     | 11/26 [00:04<00:05,  2.95it/s, Loss=5.5282, Avg Loss=5.5347]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Batch 10, Loss: 5.5282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43:  81%|████████  | 21/26 [00:06<00:01,  3.45it/s, Loss=5.5350, Avg Loss=5.5342]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Batch 20, Loss: 5.5350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43: 100%|██████████| 26/26 [00:08<00:00,  3.03it/s, Loss=5.5430, Avg Loss=5.5338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 - Train Loss: 5.533814, LR: 5.00e-06, Time: 8.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44:   4%|▍         | 1/26 [00:00<00:22,  1.12it/s, Loss=5.5290, Avg Loss=5.5290]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Batch 0, Loss: 5.5290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44:  42%|████▏     | 11/26 [00:04<00:05,  2.66it/s, Loss=5.5300, Avg Loss=5.5312]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Batch 10, Loss: 5.5300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44:  81%|████████  | 21/26 [00:08<00:01,  3.33it/s, Loss=5.5462, Avg Loss=5.5326]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Batch 20, Loss: 5.5462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44: 100%|██████████| 26/26 [00:09<00:00,  2.65it/s, Loss=5.5332, Avg Loss=5.5335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 - Train Loss: 5.533471, LR: 5.00e-06, Time: 9.82s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45:   4%|▍         | 1/26 [00:00<00:20,  1.24it/s, Loss=5.5330, Avg Loss=5.5330]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Batch 0, Loss: 5.5330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45:  42%|████▏     | 11/26 [00:04<00:04,  3.06it/s, Loss=5.5342, Avg Loss=5.5349]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Batch 10, Loss: 5.5342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45:  81%|████████  | 21/26 [00:06<00:01,  3.13it/s, Loss=5.5324, Avg Loss=5.5359]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Batch 20, Loss: 5.5324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45: 100%|██████████| 26/26 [00:08<00:00,  3.07it/s, Loss=5.5280, Avg Loss=5.5348]\n",
      "Evaluating Epoch 45: 100%|██████████| 7/7 [00:01<00:00,  5.05it/s, Val Loss=5.2278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45/100\n",
      "Train Loss: 5.534780\n",
      "Val Loss: 5.508954\n",
      "Val mean similarity: -0.0040\n",
      "Learning Rate: 5.00e-06\n",
      "Epoch Time: 9.87s, Total Time: 418.94s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46:   4%|▍         | 1/26 [00:00<00:19,  1.26it/s, Loss=5.5287, Avg Loss=5.5287]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Batch 0, Loss: 5.5287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46:  42%|████▏     | 11/26 [00:04<00:04,  3.12it/s, Loss=5.5324, Avg Loss=5.5323]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Batch 10, Loss: 5.5324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46:  81%|████████  | 21/26 [00:06<00:01,  3.42it/s, Loss=5.5397, Avg Loss=5.5338]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Batch 20, Loss: 5.5397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 26/26 [00:08<00:00,  3.04it/s, Loss=5.5346, Avg Loss=5.5326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 - Train Loss: 5.532583, LR: 2.50e-06, Time: 8.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47:   4%|▍         | 1/26 [00:00<00:20,  1.22it/s, Loss=5.5328, Avg Loss=5.5328]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Batch 0, Loss: 5.5328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47:  42%|████▏     | 11/26 [00:03<00:04,  3.66it/s, Loss=5.5143, Avg Loss=5.5302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Batch 10, Loss: 5.5143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47:  81%|████████  | 21/26 [00:06<00:01,  3.02it/s, Loss=5.5266, Avg Loss=5.5317]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Batch 20, Loss: 5.5266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47: 100%|██████████| 26/26 [00:08<00:00,  3.00it/s, Loss=5.5299, Avg Loss=5.5317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 - Train Loss: 5.531744, LR: 2.50e-06, Time: 8.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48:   4%|▍         | 1/26 [00:00<00:21,  1.15it/s, Loss=5.5407, Avg Loss=5.5407]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Batch 0, Loss: 5.5407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48:  42%|████▏     | 11/26 [00:07<00:07,  2.07it/s, Loss=5.5295, Avg Loss=5.5363]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Batch 10, Loss: 5.5295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48:  81%|████████  | 21/26 [00:10<00:01,  3.55it/s, Loss=5.5331, Avg Loss=5.5347]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Batch 20, Loss: 5.5331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48: 100%|██████████| 26/26 [00:12<00:00,  2.08it/s, Loss=5.5205, Avg Loss=5.5338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 - Train Loss: 5.533798, LR: 2.50e-06, Time: 12.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49:   4%|▍         | 1/26 [00:00<00:22,  1.11it/s, Loss=5.5294, Avg Loss=5.5294]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Batch 0, Loss: 5.5294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49:  42%|████▏     | 11/26 [00:03<00:04,  3.38it/s, Loss=5.5187, Avg Loss=5.5332]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Batch 10, Loss: 5.5187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49:  81%|████████  | 21/26 [00:06<00:01,  3.52it/s, Loss=5.5306, Avg Loss=5.5326]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Batch 20, Loss: 5.5306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 26/26 [00:08<00:00,  3.03it/s, Loss=5.5346, Avg Loss=5.5328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 - Train Loss: 5.532756, LR: 2.50e-06, Time: 8.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50:   4%|▍         | 1/26 [00:01<00:25,  1.04s/it, Loss=5.5234, Avg Loss=5.5234]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Batch 0, Loss: 5.5234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50:  42%|████▏     | 11/26 [00:04<00:05,  2.96it/s, Loss=5.5268, Avg Loss=5.5304]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Batch 10, Loss: 5.5268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50:  81%|████████  | 21/26 [00:07<00:01,  3.47it/s, Loss=5.5389, Avg Loss=5.5310]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Batch 20, Loss: 5.5389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50: 100%|██████████| 26/26 [00:08<00:00,  3.02it/s, Loss=5.5337, Avg Loss=5.5306]\n",
      "Evaluating Epoch 50: 100%|██████████| 7/7 [00:01<00:00,  4.68it/s, Val Loss=5.2250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/100\n",
      "Train Loss: 5.530555\n",
      "Val Loss: 5.510104\n",
      "Val mean similarity: 0.0118\n",
      "Learning Rate: 2.50e-06\n",
      "Epoch Time: 10.12s, Total Time: 467.40s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51:   4%|▍         | 1/26 [00:00<00:24,  1.04it/s, Loss=5.5326, Avg Loss=5.5326]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Batch 0, Loss: 5.5326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51:  42%|████▏     | 11/26 [00:03<00:04,  3.39it/s, Loss=5.5304, Avg Loss=5.5329]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Batch 10, Loss: 5.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51:  81%|████████  | 21/26 [00:07<00:01,  2.88it/s, Loss=5.5269, Avg Loss=5.5319]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Batch 20, Loss: 5.5269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51: 100%|██████████| 26/26 [00:10<00:00,  2.58it/s, Loss=5.5222, Avg Loss=5.5319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 - Train Loss: 5.531884, LR: 2.50e-06, Time: 10.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52:   4%|▍         | 1/26 [00:00<00:24,  1.03it/s, Loss=5.5192, Avg Loss=5.5192]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Batch 0, Loss: 5.5192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52:  42%|████▏     | 11/26 [00:04<00:04,  3.25it/s, Loss=5.5340, Avg Loss=5.5342]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Batch 10, Loss: 5.5340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52:  81%|████████  | 21/26 [00:06<00:01,  3.72it/s, Loss=5.5210, Avg Loss=5.5314]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Batch 20, Loss: 5.5210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52: 100%|██████████| 26/26 [00:08<00:00,  3.04it/s, Loss=5.5313, Avg Loss=5.5321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 - Train Loss: 5.532111, LR: 2.50e-06, Time: 8.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53:   4%|▍         | 1/26 [00:00<00:21,  1.17it/s, Loss=5.5246, Avg Loss=5.5246]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Batch 0, Loss: 5.5246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53:  42%|████▏     | 11/26 [00:03<00:04,  3.23it/s, Loss=5.5280, Avg Loss=5.5285]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Batch 10, Loss: 5.5280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53:  81%|████████  | 21/26 [00:06<00:01,  3.44it/s, Loss=5.5424, Avg Loss=5.5297]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Batch 20, Loss: 5.5424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53: 100%|██████████| 26/26 [00:08<00:00,  3.10it/s, Loss=5.5500, Avg Loss=5.5302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 - Train Loss: 5.530188, LR: 2.50e-06, Time: 8.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54:   4%|▍         | 1/26 [00:00<00:21,  1.14it/s, Loss=5.5277, Avg Loss=5.5277]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Batch 0, Loss: 5.5277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54:  42%|████▏     | 11/26 [00:04<00:05,  2.86it/s, Loss=5.5308, Avg Loss=5.5296]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Batch 10, Loss: 5.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54:  81%|████████  | 21/26 [00:07<00:01,  3.65it/s, Loss=5.5157, Avg Loss=5.5293]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Batch 20, Loss: 5.5157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54: 100%|██████████| 26/26 [00:08<00:00,  2.95it/s, Loss=5.5220, Avg Loss=5.5302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 - Train Loss: 5.530225, LR: 2.50e-06, Time: 8.81s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55:   4%|▍         | 1/26 [00:00<00:22,  1.13it/s, Loss=5.5199, Avg Loss=5.5199]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Batch 0, Loss: 5.5199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55:  42%|████▏     | 11/26 [00:04<00:04,  3.02it/s, Loss=5.5286, Avg Loss=5.5330]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Batch 10, Loss: 5.5286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55:  81%|████████  | 21/26 [00:07<00:01,  3.47it/s, Loss=5.5298, Avg Loss=5.5333]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Batch 20, Loss: 5.5298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55: 100%|██████████| 26/26 [00:09<00:00,  2.66it/s, Loss=5.5325, Avg Loss=5.5322]\n",
      "Evaluating Epoch 55: 100%|██████████| 7/7 [00:01<00:00,  4.68it/s, Val Loss=5.2248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55/100\n",
      "Train Loss: 5.532163\n",
      "Val Loss: 5.511070\n",
      "Val mean similarity: 0.0050\n",
      "Learning Rate: 2.50e-06\n",
      "Epoch Time: 11.27s, Total Time: 515.39s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56:   4%|▍         | 1/26 [00:00<00:20,  1.21it/s, Loss=5.5460, Avg Loss=5.5460]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Batch 0, Loss: 5.5460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56:  42%|████▏     | 11/26 [00:03<00:04,  3.07it/s, Loss=5.5467, Avg Loss=5.5302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Batch 10, Loss: 5.5467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56:  81%|████████  | 21/26 [00:06<00:01,  3.38it/s, Loss=5.5247, Avg Loss=5.5319]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Batch 20, Loss: 5.5247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56: 100%|██████████| 26/26 [00:08<00:00,  3.08it/s, Loss=5.5411, Avg Loss=5.5321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 - Train Loss: 5.532070, LR: 2.50e-06, Time: 8.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57:   4%|▍         | 1/26 [00:00<00:21,  1.19it/s, Loss=5.5215, Avg Loss=5.5215]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Batch 0, Loss: 5.5215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57:  42%|████▏     | 11/26 [00:03<00:04,  3.30it/s, Loss=5.5079, Avg Loss=5.5273]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Batch 10, Loss: 5.5079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57:  81%|████████  | 21/26 [00:06<00:01,  3.07it/s, Loss=5.5146, Avg Loss=5.5299]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Batch 20, Loss: 5.5146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57: 100%|██████████| 26/26 [00:08<00:00,  3.03it/s, Loss=5.5406, Avg Loss=5.5317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 - Train Loss: 5.531710, LR: 2.50e-06, Time: 8.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58:   4%|▍         | 1/26 [00:01<00:26,  1.08s/it, Loss=5.5280, Avg Loss=5.5280]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Batch 0, Loss: 5.5280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58:  42%|████▏     | 11/26 [00:04<00:04,  3.57it/s, Loss=5.5457, Avg Loss=5.5308]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Batch 10, Loss: 5.5457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58:  81%|████████  | 21/26 [00:07<00:01,  3.41it/s, Loss=5.5259, Avg Loss=5.5291]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Batch 20, Loss: 5.5259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58: 100%|██████████| 26/26 [00:08<00:00,  2.91it/s, Loss=5.5106, Avg Loss=5.5286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 - Train Loss: 5.528578, LR: 2.50e-06, Time: 8.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59:   4%|▍         | 1/26 [00:00<00:20,  1.21it/s, Loss=5.5179, Avg Loss=5.5179]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Batch 0, Loss: 5.5179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59:  42%|████▏     | 11/26 [00:04<00:05,  2.82it/s, Loss=5.5257, Avg Loss=5.5286]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Batch 10, Loss: 5.5257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59:  81%|████████  | 21/26 [00:08<00:01,  3.25it/s, Loss=5.5506, Avg Loss=5.5327]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Batch 20, Loss: 5.5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59: 100%|██████████| 26/26 [00:09<00:00,  2.68it/s, Loss=5.5228, Avg Loss=5.5322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 - Train Loss: 5.532243, LR: 2.50e-06, Time: 9.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60:   4%|▍         | 1/26 [00:00<00:21,  1.14it/s, Loss=5.5432, Avg Loss=5.5432]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Batch 0, Loss: 5.5432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60:  42%|████▏     | 11/26 [00:03<00:04,  3.35it/s, Loss=5.5560, Avg Loss=5.5302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Batch 10, Loss: 5.5560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60:  81%|████████  | 21/26 [00:06<00:01,  3.33it/s, Loss=5.5188, Avg Loss=5.5308]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Batch 20, Loss: 5.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60: 100%|██████████| 26/26 [00:08<00:00,  3.00it/s, Loss=5.5371, Avg Loss=5.5308]\n",
      "Evaluating Epoch 60: 100%|██████████| 7/7 [00:01<00:00,  5.05it/s, Val Loss=5.2236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/100\n",
      "Train Loss: 5.530762\n",
      "Val Loss: 5.512265\n",
      "Val mean similarity: 0.0007\n",
      "Learning Rate: 2.50e-06\n",
      "Epoch Time: 10.05s, Total Time: 561.14s\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61:   4%|▍         | 1/26 [00:00<00:20,  1.19it/s, Loss=5.5354, Avg Loss=5.5354]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Batch 0, Loss: 5.5354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61:  42%|████▏     | 11/26 [00:04<00:04,  3.21it/s, Loss=5.5306, Avg Loss=5.5291]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Batch 10, Loss: 5.5306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61:  81%|████████  | 21/26 [00:07<00:01,  3.27it/s, Loss=5.5386, Avg Loss=5.5322]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Batch 20, Loss: 5.5386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61: 100%|██████████| 26/26 [00:08<00:00,  3.00it/s, Loss=5.5183, Avg Loss=5.5311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 - Train Loss: 5.531056, LR: 2.50e-06, Time: 8.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62:   4%|▍         | 1/26 [00:01<00:26,  1.08s/it, Loss=5.5277, Avg Loss=5.5277]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Batch 0, Loss: 5.5277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62:  42%|████▏     | 11/26 [00:03<00:04,  3.42it/s, Loss=5.5345, Avg Loss=5.5282]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Batch 10, Loss: 5.5345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62:  81%|████████  | 21/26 [00:06<00:01,  3.26it/s, Loss=5.5173, Avg Loss=5.5282]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Batch 20, Loss: 5.5173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62: 100%|██████████| 26/26 [00:08<00:00,  2.96it/s, Loss=5.5382, Avg Loss=5.5295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 - Train Loss: 5.529541, LR: 2.50e-06, Time: 8.92s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63:   4%|▍         | 1/26 [00:01<00:25,  1.01s/it, Loss=5.5234, Avg Loss=5.5234]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Batch 0, Loss: 5.5234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63:  42%|████▏     | 11/26 [00:05<00:05,  2.75it/s, Loss=5.5253, Avg Loss=5.5273]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Batch 10, Loss: 5.5253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63:  81%|████████  | 21/26 [00:08<00:01,  3.59it/s, Loss=5.5242, Avg Loss=5.5289]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Batch 20, Loss: 5.5242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63:  85%|████████▍ | 22/26 [00:08<00:01,  2.51it/s, Loss=5.5305, Avg Loss=5.5290]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m train_loss, batch_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Get current learning rate after scheduler step\u001b[39;00m\n\u001b[1;32m     27\u001b[0m current_lr \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[27], line 26\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, device, epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(mol_features, spec_features)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Track loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CSU-MS2/lib/python3.8/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Training history for plotting\n",
    "train_history = {\n",
    "    'epochs': [],\n",
    "    'train_losses': [],\n",
    "    'val_losses': [],\n",
    "    'val_similarities': [],\n",
    "    'learning_rates': [],  \n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Training phase\n",
    "    train_loss, batch_losses = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, DEVICE, epoch\n",
    "    )    \n",
    "\n",
    "    # Get current learning rate after scheduler step\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Log training loss every epoch\n",
    "    logger.report_scalar(\"Loss\", \"Train\", iteration=epoch, value=train_loss)\n",
    "    \n",
    "    # Validation phase (every n epochs)\n",
    "    if epoch % eval_every_n_epochs == 0:\n",
    "        val_loss, val_similarity = evaluate_model(\n",
    "            model, val_loader, criterion, DEVICE, epoch\n",
    "        )\n",
    "        \n",
    "    \n",
    "        # # Step scheduler every epoch\n",
    "        # scheduler.step(val_loss)\n",
    "        \n",
    "        # Log results\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Log validation metrics to ClearML\n",
    "        logger.report_scalar(\"Loss\", \"Validation\", iteration=epoch, value=val_loss)\n",
    "        logger.report_scalar(\"Similarity\", \"Cosine Similarity\", iteration=epoch, value=val_similarity)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.6f}\")\n",
    "        print(f\"Val Loss: {val_loss:.6f}\")\n",
    "        print(f\"Val mean similarity: {val_similarity:.4f}\")\n",
    "        print(f\"Learning Rate: {current_lr:.2e}\")\n",
    "        print(f\"Epoch Time: {epoch_time:.2f}s, Total Time: {total_time:.2f}s\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Store history\n",
    "        train_history['epochs'].append(int(epoch))\n",
    "        train_history['train_losses'].append(float(train_loss))\n",
    "        train_history['val_losses'].append(float(val_loss))\n",
    "        train_history['val_similarities'].append(float(val_similarity))\n",
    "        train_history['learning_rates'].append(float(current_lr))\n",
    "        \n",
    "        # Save checkpoint\n",
    "        # save_checkpoint(\n",
    "        #     model, optimizer, epoch, \n",
    "        #     train_loss, val_loss, checkpoint_dir\n",
    "        # )\n",
    "        \n",
    "        if epoch % (eval_every_n_epochs * 2) == 0 and len(train_history['epochs']) > 1:\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "            \n",
    "            # Loss plot\n",
    "            epochs_list = train_history['epochs']\n",
    "            ax1.plot(epochs_list, train_history['train_losses'], 'b-', label='Train Loss', linewidth=2)\n",
    "            ax1.plot(epochs_list, train_history['val_losses'], 'r-', label='Val Loss', linewidth=2)\n",
    "            ax1.set_xlabel('Epoch')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.set_title('Training and Validation Loss')\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Similarity plot\n",
    "            ax2.plot(epochs_list, train_history['val_similarities'], 'g-', linewidth=2)\n",
    "            ax2.set_xlabel('Epoch')\n",
    "            ax2.set_ylabel('Cosine Similarity')\n",
    "            ax2.set_title('Validation Cosine Similarity')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Learning rate plot\n",
    "            ax3.plot(epochs_list, train_history['learning_rates'], 'purple', linewidth=2)\n",
    "            ax3.set_xlabel('Epoch')\n",
    "            ax3.set_ylabel('Learning Rate')\n",
    "            ax3.set_title('Learning Rate Schedule')\n",
    "            ax3.set_yscale('log') \n",
    "            ax3.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            logger.report_matplotlib_figure(\"Training Progress\", \"Loss, Similarity and LR\", iteration=epoch, figure=plt)\n",
    "            plt.close()\n",
    "    \n",
    "    else:\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.6f}, LR: {current_lr:.2e}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "# Final summary logging\n",
    "print(\"\\nTraining completed!\")\n",
    "total_training_time = (time.time() - start_time)/3600\n",
    "print(f\"Total training time: {total_training_time:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58b84058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log final metrics\n",
    "logger.report_single_value(\"Total Training Time (hours)\", total_training_time)\n",
    "logger.report_single_value(\"Best Validation Loss\", min(train_history['val_losses']) if train_history['val_losses'] else float('inf'))\n",
    "logger.report_single_value(\"Best Cosine Similarity\", max(train_history['val_similarities']) if train_history['val_similarities'] else 0.0)\n",
    "logger.report_single_value(\"Total Epochs\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2a3d3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA memory stats reset\n",
      "============================================================\n",
      "GPU MEMORY ANALYSIS\n",
      "============================================================\n",
      "CUDA available: 2 device(s)\n",
      "\n",
      "GPU 0: NVIDIA A100 80GB PCIe\n",
      "----------------------------------------\n",
      "Total Memory:     79.25 GB\n",
      "Currently Allocated: 0.00 GB (0.0%)\n",
      "Currently Reserved:  0.00 GB (0.0%)\n",
      "Peak Allocated:   0.00 GB (0.0%)\n",
      "Peak Reserved:    0.00 GB (0.0%)\n",
      "Free Memory:      79.25 GB\n",
      "\n",
      "GPU 1: NVIDIA A100 80GB PCIe\n",
      "----------------------------------------\n",
      "Total Memory:     79.25 GB\n",
      "Currently Allocated: 0.10 GB (0.1%)\n",
      "Currently Reserved:  0.26 GB (0.3%)\n",
      "Peak Allocated:   0.10 GB (0.1%)\n",
      "Peak Reserved:    0.26 GB (0.3%)\n",
      "Free Memory:      79.00 GB\n",
      "Memory Fragmentation: 60.0%\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: Emergency GPU cleanup and memory monitoring\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "def emergency_gpu_cleanup():\n",
    "    \"\"\"Emergency cleanup to free all GPU memory\"\"\"\n",
    "    try:\n",
    "        # Clear all cached tensors\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "        # Force garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Try to reset CUDA context (nuclear option)\n",
    "        if torch.cuda.is_available():\n",
    "            try:\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "                print(\"CUDA memory stats reset\")\n",
    "            except:\n",
    "                print(\"Could not reset CUDA memory stats\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleanup: {e}\")\n",
    "\n",
    "def print_gpu_memory_usage():\n",
    "    \"\"\"Print comprehensive GPU memory usage\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"GPU MEMORY ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device_count = torch.cuda.device_count()\n",
    "        print(f\"CUDA available: {device_count} device(s)\")\n",
    "        \n",
    "        for i in range(device_count):\n",
    "            try:\n",
    "                torch.cuda.set_device(i)\n",
    "                device_name = torch.cuda.get_device_name(i)\n",
    "                \n",
    "                # Memory in bytes\n",
    "                allocated = torch.cuda.memory_allocated(i)\n",
    "                reserved = torch.cuda.memory_reserved(i)\n",
    "                max_allocated = torch.cuda.max_memory_allocated(i)\n",
    "                max_reserved = torch.cuda.max_memory_reserved(i)\n",
    "                \n",
    "                # Get total GPU memory\n",
    "                total_memory = torch.cuda.get_device_properties(i).total_memory\n",
    "                \n",
    "                print(f\"\\nGPU {i}: {device_name}\")\n",
    "                print(\"-\" * 40)\n",
    "                print(f\"Total Memory:     {total_memory / 1024**3:.2f} GB\")\n",
    "                print(f\"Currently Allocated: {allocated / 1024**3:.2f} GB ({allocated/total_memory*100:.1f}%)\")\n",
    "                print(f\"Currently Reserved:  {reserved / 1024**3:.2f} GB ({reserved/total_memory*100:.1f}%)\")\n",
    "                print(f\"Peak Allocated:   {max_allocated / 1024**3:.2f} GB ({max_allocated/total_memory*100:.1f}%)\")\n",
    "                print(f\"Peak Reserved:    {max_reserved / 1024**3:.2f} GB ({max_reserved/total_memory*100:.1f}%)\")\n",
    "                print(f\"Free Memory:      {(total_memory - reserved) / 1024**3:.2f} GB\")\n",
    "                \n",
    "                # Memory fragmentation analysis\n",
    "                if reserved > 0:\n",
    "                    fragmentation = (reserved - allocated) / reserved * 100\n",
    "                    print(f\"Memory Fragmentation: {fragmentation:.1f}%\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading GPU {i} memory: {e}\")\n",
    "                \n",
    "    elif torch.backends.mps.is_available():\n",
    "        print(\"MPS (Metal Performance Shaders) available\")\n",
    "        print(\"Note: MPS memory monitoring not directly available\")\n",
    "        \n",
    "        # Get system memory as proxy\n",
    "        mem = psutil.virtual_memory()\n",
    "        print(f\"System Memory: {mem.total / 1024**3:.2f} GB\")\n",
    "        print(f\"Available Memory: {mem.available / 1024**3:.2f} GB\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No GPU acceleration available - using CPU\")\n",
    "        \n",
    "        # Show CPU memory usage\n",
    "        mem = psutil.virtual_memory()\n",
    "        print(f\"System Memory: {mem.total / 1024**3:.2f} GB\")\n",
    "        print(f\"Available Memory: {mem.available / 1024**3:.2f} GB\")\n",
    "        print(f\"Used Memory: {mem.used / 1024**3:.2f} GB ({mem.percent:.1f}%)\")\n",
    "\n",
    "def print_model_memory_usage(model):\n",
    "    \"\"\"Calculate and print model memory usage\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"MODEL MEMORY ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Parameter memory\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "    \n",
    "    # Count parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    print(f\"Model Parameters:\")\n",
    "    print(f\"  Trainable: {trainable_params:,}\")\n",
    "    print(f\"  Total: {total_params:,}\")\n",
    "    print(f\"  Non-trainable: {total_params - trainable_params:,}\")\n",
    "    \n",
    "    print(f\"\\nModel Memory:\")\n",
    "    print(f\"  Parameters: {param_size / 1024**2:.2f} MB\")\n",
    "    print(f\"  Buffers: {buffer_size / 1024**2:.2f} MB\")\n",
    "    print(f\"  Total Model: {(param_size + buffer_size) / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Estimate training memory (rough approximation)\n",
    "    # Forward pass ≈ model size, backward pass ≈ 2x model size, optimizer ≈ 2x model size\n",
    "    estimated_training_memory = (param_size + buffer_size) * 5  # Conservative estimate\n",
    "    print(f\"  Estimated Training Memory: {estimated_training_memory / 1024**2:.2f} MB\")\n",
    "\n",
    "def monitor_batch_memory(device, batch_size):\n",
    "    \"\"\"Monitor memory usage during a training step\"\"\"\n",
    "    if torch.cuda.is_available() and device == 'cuda':\n",
    "        print(f\"\\nBatch Memory Analysis (Batch Size: {batch_size}):\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Memory before\n",
    "        mem_before = torch.cuda.memory_allocated() / 1024**2\n",
    "        \n",
    "        # Simulate memory usage estimation\n",
    "        print(f\"Memory before batch: {mem_before:.2f} MB\")\n",
    "        \n",
    "        return mem_before\n",
    "    return 0\n",
    "\n",
    "# Run emergency cleanup first\n",
    "emergency_gpu_cleanup()\n",
    "\n",
    "# Print initial memory status\n",
    "print_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dfe72c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the task\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSU-MS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
